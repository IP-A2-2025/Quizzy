[{content={parts=[{text=```
--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following algorithms are part of clustering?
--InteriorSeparator--
(right) K-means
(right) Hierarchical clustering
(wrong) Linear Regression
(wrong) Support Vector Machine
--InteriorSeparator--
easy
--InteriorSeparator--
1
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the main idea behind Ward's metric in hierarchical clustering?
--InteriorSeparator--
Minimize the increase in the sum of squares when merging clusters.
--InteriorSeparator--
medium
--InteriorSeparator--
11
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
In hierarchical clustering, what are the common linkage methods?
--InteriorSeparator--
(right) Single-linkage
(right) Complete-linkage
(right) Average-linkage
(wrong) Ward-linkage
--InteriorSeparator--
easy
--InteriorSeparator--
3
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the main goal of K-means clustering?
--InteriorSeparator--
To partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.
--InteriorSeparator--
easy
--InteriorSeparator--
33
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What is the consequence of outlier data in k-means clustering?
--InteriorSeparator--
(right) Can result in erroneous modelling
(right) May lead to poor/inaccurate cluster formation
(wrong) Always improves cluster accuracy
(wrong) Doesn't affect cluster formation
--InteriorSeparator--
medium
--InteriorSeparator--
48
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Is it guaranteed that the K-means algorithm will achieve global minimum of the objective function?
--InteriorSeparator--
No, the K-means algorithm is susceptible to local optima.
--InteriorSeparator--
hard
--InteriorSeparator--
68
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following is true about the EM algorithm for Gaussian Mixture Models (GMM)?
--InteriorSeparator--
(right) It is an iterative method for finding maximum likelihood estimates of parameters in probabilistic models
(wrong) It always converges to the global optimum solution
(wrong) It can only be used with Gaussian distributions
(wrong) It does not require an initial guess for parameters.
--InteriorSeparator--
medium
--InteriorSeparator--
86
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the E-step in the EM algorithm?
--InteriorSeparator--
Compute the expectation (i.e., a posteriori probabilities) of latent variables
--InteriorSeparator--
medium
--InteriorSeparator--
107
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What does the M-step do in the EM algorithm?
--InteriorSeparator--
Maximizes the expectation calculated in the E-step to update the parameters of the model.
--InteriorSeparator--
medium
--InteriorSeparator--
107
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What distribution is used in the general EM algorithm for GMM?
--InteriorSeparator--
categorical
--InteriorSeparator--
hard
--InteriorSeparator--
105
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the EM algorithm, what is a latent variable?
--InteriorSeparator--
A variable that is not directly observed but is inferred from other variables.
--InteriorSeparator--
medium
--InteriorSeparator--
132
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What parameters are estimated by the EM algorithm when applied to a Gaussian Mixture Model?
--InteriorSeparator--
(right) Means of the Gaussians
(right) Covariance matrices of the Gaussians
(right) Mixing proportions (priors) of the Gaussians
(wrong) Number of clusters
--InteriorSeparator--
easy
--InteriorSeparator--
133
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the impact of high covariance between instances in clustering?
--InteriorSeparator--
Covariance represents the degree to which instances/features change together. High covariance may indicate that instances cluster well or contain data redundancy.
--InteriorSeparator--
hard
--InteriorSeparator--
116
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Why is reinitialization recommended for the K-means algorithm?
--InteriorSeparator--
The algorithm is susceptible to local optima.
--InteriorSeparator--
hard
--InteriorSeparator--
143
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
How is distance calculated with Euclidean Distance in K-means algorithm?
--InteriorSeparator--
It is the measure used to determine if/how close a data point is to the central point
--InteriorSeparator--
easy
--InteriorSeparator--
35
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
In Kernelized K-means, what is the advantage of using kernel functions?
--InteriorSeparator--
(right) Allows for non-linear cluster boundaries
(wrong) Simplifies the computation
(right) Maps data to a higher dimensional space
(wrong) Always converges faster
--InteriorSeparator--
medium
--InteriorSeparator--
79
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What happens to cluster centers with no data points associated during a k-means update step?
--InteriorSeparator--
The cluster center will not move.
--InteriorSeparator--
medium
--InteriorSeparator--
42
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
When applying hierarchical clustering, what determines which clusters are merged at each step?
--InteriorSeparator--
(right) The distance between clusters based on the chosen linkage method
(wrong) The size of the clusters
(wrong) Random selection
(wrong) User-defined rules
--InteriorSeparator--
easy
--InteriorSeparator--
4
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the relationship between Single-linkage hierarchies and Minimum Spanning Trees (MSTs)?
--InteriorSeparator--
Kruskal's algorithm is exactly analogous to the single-linkage bottom-up clustering algorithm.
--InteriorSeparator--
hard
--InteriorSeparator--
32
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
With agglomerative hierarchical clustering, where does the sum of squares start out?
--InteriorSeparator--
At zero.
--InteriorSeparator--
hard
--InteriorSeparator--
15
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
How is a new data point assigned with k-means?
--InteriorSeparator--
Each new data point is assigned to the nearest centroid.
--InteriorSeparator--
hard
--InteriorSeparator--
50
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
How can one decide if the number of clusters is too big or too small?
--InteriorSeparator--
(right) If the cost of merging increases a lot, it is probably going too far, and losing a lot of structure
(wrong) If the cost is still low, k is the right size
(wrong) When the merging cost has stabilized, k is the right size
(wrong) Cost has nothing to do with cluster number selection
--InteriorSeparator--
hard
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What metric can be used for hierarchical clustering?
--InteriorSeparator--
Ward's metric.
--InteriorSeparator--
medium
--InteriorSeparator--
10
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is divisive clustering?
--InteriorSeparator--
A top-down hierarchical clustering approach.
--InteriorSeparator--
medium
--InteriorSeparator--
27
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What is an indicator matrix?
--InteriorSeparator--
(right) Represents cluster assignments of data points
(wrong) Used to calculate total variance
(right) Has 1 if data point i belongs to cluster j, and 0 otherwise.
(wrong) It's a Euclidean calculation
--InteriorSeparator--
hard
--InteriorSeparator--
70
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the termination condition for the EM Algorithm?
--InteriorSeparator--
None of the values in L changed from the previous iteration.
--InteriorSeparator--
hard
--InteriorSeparator--
64
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are some useful properties of EM or GMM algorithms?
--InteriorSeparator--
(right) Repeatedly trying to guess the unknown zfs.
(wrong) Never susceptible to local optima.
(wrong) Is the same as k-means
(right) has soft assignments.
--InteriorSeparator--
hard
--InteriorSeparator--
143
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the other name for Single-linkage clustering?
--InteriorSeparator--
Nearest neighbor clustering.
--InteriorSeparator--
hard
--InteriorSeparator--
5
--FlashCardSeparator--
```}], role=model}, finishReason=STOP, citationMetadata={citationSources=[{startIndex=1036, endIndex=1217, uri=https://patents.google.com/patent/WO2023066548A1/en}]}, avgLogprobs=-0.36304351048614303}]