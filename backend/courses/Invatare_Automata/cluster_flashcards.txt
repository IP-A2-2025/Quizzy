[{content={parts=[{text=--FlashCardSeparator--
Single
--InteriorSeparator--
What is the primary difference between classification and clustering?
--InteriorSeparator--
Classification is supervised learning with labeled data, while clustering is unsupervised learning without labeled data.
--InteriorSeparator--
easy
--InteriorSeparator--
3
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the main goal of clustering?
--InteriorSeparator--
To place similar objects in the same group and dissimilar objects in different groups.
--InteriorSeparator--
easy
--InteriorSeparator--
4
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What type of structure does hierarchical clustering produce?
--InteriorSeparator--
A tree of groups/clusters.
--InteriorSeparator--
easy
--InteriorSeparator--
5
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following are the main uses of clustering?
--InteriorSeparator--
(right) Generalization
(right) Exploratory Data Analysis (EDA)
(wrong) Supervised Learning
(wrong) Data Labelling
--InteriorSeparator--
medium
--InteriorSeparator--
8, 9
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What are the two main approaches to hierarchical clustering?
--InteriorSeparator--
Bottom-up (agglomerative) and Top-down (divisive).
--InteriorSeparator--
easy
--InteriorSeparator--
10
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which similarity functions are commonly used in hierarchical clustering?
--InteriorSeparator--
(right) Single link
(right) Complete link
(right) Group average
(wrong) Maximum entropy
--InteriorSeparator--
easy
--InteriorSeparator--
15
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a potential disadvantage of single-link clustering?
--InteriorSeparator--
It can produce elongated clusters due to the "chaining effect."
--InteriorSeparator--
medium
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a good compromise between single-link and complete-link clustering?
--InteriorSeparator--
Group-average agglomerative clustering.
--InteriorSeparator--
medium
--InteriorSeparator--
18
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a hard assignment in clustering?
--InteriorSeparator--
Each object is assigned to one and only one cluster.
--InteriorSeparator--
easy
--InteriorSeparator--
21
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the main idea behind the k-means algorithm?
--InteriorSeparator--
To partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.
--InteriorSeparator--
medium
--InteriorSeparator--
23
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are the general steps of the k-means algorithm?
--InteriorSeparator--
(right) Select k initial centers.
(right) Assign each object to the closest center.
(right) Recompute the cluster means based on the objects assigned to each cluster.
(wrong) Randomly assign objects to clusters
--InteriorSeparator--
medium
--InteriorSeparator--
23
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What does GMM stand for?
--InteriorSeparator--
Gaussian Mixture Modeling
--InteriorSeparator--
easy
--InteriorSeparator--
2
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In Gaussian Mixture Modeling, what is assumed about the data generation process?
--InteriorSeparator--
Each instance is generated by choosing one of k Gaussians and then randomly sampling from that Gaussian.
--InteriorSeparator--
medium
--InteriorSeparator--
25
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the context of Gaussian Mixture Modeling, what do the variables zij represent?
--InteriorSeparator--
zij is 1 if the ith instance was generated by the jth Gaussian and 0 otherwise.
--InteriorSeparator--
medium
--InteriorSeparator--
27
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What does the EM algorithm aim to find in Gaussian Mixture Modeling?
--InteriorSeparator--
A local maximum of the expected value of the log-likelihood of the complete data.
--InteriorSeparator--
hard
--InteriorSeparator--
30
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What are the two main steps of the EM algorithm?
--InteriorSeparator--
Estimation (E) step and Maximization (M) step.
--InteriorSeparator--
medium
--InteriorSeparator--
31
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the Estimation step of EM for GMM, what is being calculated?
--InteriorSeparator--
The expected value of the hidden variable Zij, given the current hypothesis.
--InteriorSeparator--
hard
--InteriorSeparator--
31
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the Maximization step of EM for GMM, what is being optimized?
--InteriorSeparator--
The parameters of the Gaussians (means), assuming that the hidden variables are equal to their expected values.
--InteriorSeparator--
hard
--InteriorSeparator--
31
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the justification for using the EM algorithm in Gaussian Mixture Modeling?
--InteriorSeparator--
It iteratively increases the likelihood of the data given the model, converging to a local maximum.
--InteriorSeparator--
hard
--InteriorSeparator--
35
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a major disadvantage of hierarchical clustering compared to non-hierarchical clustering?
--InteriorSeparator--
It is less efficient, requiring at least n x n similarity coefficient computations.
--InteriorSeparator--
medium
--InteriorSeparator--
36
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following statements are true regarding the k-means algorithm?
--InteriorSeparator--
(right) It is conceptually the simplest clustering method.
(wrong) It guarantees finding the global optimum.
(right) It is not suitable for nominal data.
(wrong) It is always more effective than EM algorithm.
--InteriorSeparator--
medium
--InteriorSeparator--
36
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the formula for calculating the average similarity of a cluster cj?
--InteriorSeparator--
s(cj) = 1 / |cj|(|cj|-1) * sum(sim(x,y)), where x, y are members of cj and x != y
--InteriorSeparator--
hard
--InteriorSeparator--
19
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Define the kulback-Leibler (KL) divergence
--InteriorSeparator--
D(P || Q) = ∑ p(x) log (p(x) / q(x)), assumes 0 log 0 = 0 and p log 0 = ∞
--InteriorSeparator--
hard
--InteriorSeparator--
14
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Define Monotonicity of the similarity function.
--InteriorSeparator--
The operation of merging must not increase the similarity: ∀c, c’, c” : min(sim(c, c’), sim(c, c”)) ≥ sim(c, c’ ∪ c”).
--InteriorSeparator--
hard
--InteriorSeparator--
12
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Describe the connection between single-link clustering and the Minimum Spanning Tree (MST).
--InteriorSeparator--
Single-link clustering is closely related to the Minimum Spanning Tree (MST) of a set of points. Of all trees connecting the set of objects, the sum of the edges of the MST is minimal.
--InteriorSeparator--
hard
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the complexity of Single-link Clustering in graph theory?
--InteriorSeparator--
O(n^2).
--InteriorSeparator--
hard
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the complexity of Complete-link Clustering in graph theory?
--InteriorSeparator--
O(n^3)
--InteriorSeparator--
hard
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the formula for the centroid of a cluster c?
--InteriorSeparator--
μ = (1 / |c|) * ∑x, where x is a member of c
--InteriorSeparator--
hard
--InteriorSeparator--
21
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What does argmax P(D|h) signify?
--InteriorSeparator--
It denotes the maximum likelihood (ML) estimates of μ1, ..., μk.
--InteriorSeparator--
hard
--InteriorSeparator--
26
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are some stopping criteria for non-hierarchical clustering algorithms?
--InteriorSeparator--
(right) Group-average similarity
(right) Likelihood of data, given the clusters
(right) Minimum Description Length (MDL) principle
(right) Mutual information between adjacent clusters
--InteriorSeparator--
medium
--InteriorSeparator--
22
--FlashCardSeparator--
}], role=model}, finishReason=STOP, citationMetadata={citationSources=[{startIndex=2665, endIndex=2846, uri=https://patents.google.com/patent/WO2023066548A1/en}, {startIndex=7562, endIndex=7717, uri=https://www.sambuz.com/doc/clustering-ppt-presentation-815642}]}, avgLogprobs=-0.1259992918082978}]