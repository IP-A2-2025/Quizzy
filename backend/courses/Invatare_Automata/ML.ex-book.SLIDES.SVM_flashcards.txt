[{content={parts=[{text=--FlashCardSeparator--
Single
--InteriorSeparator--
What are the three main categories of Support Vector Machines (SVMs) discussed?
--InteriorSeparator--
Hard margin SVM, Soft margin SVM (C-SVM), and Other SVM-like Optimization problems.
--InteriorSeparator--
easy
--InteriorSeparator--
1
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the formula for the perpendicular distance of a point x0 to a hyperplane defined by wa + b = 0?
--InteriorSeparator--
d(x0, x*) = |w * x0 + b| / ||w||
--InteriorSeparator--
medium
--InteriorSeparator--
3
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following is part of the primal form of the SVM optimization problem?
--InteriorSeparator--
(right) Minimizing 1/2 * ||w||^2
(right) Subject to yi(w * xi) >= 1 for all i
(wrong) Maximizing ||w||
(wrong) Subject to yi(w * xi) <= 1 for all i
--InteriorSeparator--
medium
--InteriorSeparator--
6
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Explain the geometrical interpretation of transforming the SVM optimization problem from equation (4) to equation (5).
--InteriorSeparator--
Corresponds to multiplying equations of linear separators of the training set by a positive (supra-unitary) constant, so that the minimum geometrical distance to training instances becomes 1.
--InteriorSeparator--
hard
--InteriorSeparator--
9
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Explain the geometrical interpretation of transforming the SVM optimization problem from equation (5) to equation (6).
--InteriorSeparator--
Corresponds to multiplying equations of linear separators of the training set by a positive (sub-unitary) constant, so that the minimum geometrical distance to training instances becomes 1.
--InteriorSeparator--
hard
--InteriorSeparator--
10
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are the key components obtained from solving the SVM optimization problem in its primal form?
--InteriorSeparator--
(right) A linear model y(x) = w * x + w0 for classification
(wrong) A non-linear model for classification
(right) Support vectors, which are the closest instances to the separator
(wrong) Only the weights 'w' for classification
--InteriorSeparator--
medium
--InteriorSeparator--
14
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What are Lagrange multipliers (αi) also referred to as?
--InteriorSeparator--
Dual variables
--InteriorSeparator--
easy
--InteriorSeparator--
15
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is Slater's condition and why is it important in the context of SVM?
--InteriorSeparator--
Guarantees that there exists w and w0 such that (w * xi + w0)yi - 1 > 0 for all i. Ensures strong duality, meaning the primal and dual problems have the same optimal value.
--InteriorSeparator--
hard
--InteriorSeparator--
16
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
According to KKT conditions, what relationship can be deduced for any i where αi > 0?
--InteriorSeparator--
(right) w * xi + w0 = yi
(wrong) w * xi + w0 > yi
(wrong) w * xi + w0 < yi
(wrong) αi = 0
--InteriorSeparator--
hard
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
How is the dual form (D) of the SVM problem related to the primal form (P)?
--InteriorSeparator--
The dual form maximizes a function LD(α) subject to constraints like αi >= 0 and Σ αiyi = 0. The solutions to (D) are linked to (P) via relationships like w = Σ αixiyi.
--InteriorSeparator--
hard
--InteriorSeparator--
21
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
How is a new instance xnew classified using the SVM model?
--InteriorSeparator--
Classified as positive if f(xnew) = w * xnew + w0 >= 0, and negative otherwise.
--InteriorSeparator--
easy
--InteriorSeparator--
22
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What operations make using kernel functions possible in the context of SVM?
--InteriorSeparator--
Scalar product operations
--InteriorSeparator--
easy
--InteriorSeparator--
23
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What do slack variables (ξi) in C-SVM allow?
--InteriorSeparator--
Allowing some training data points to be misclassified.
--InteriorSeparator--
easy
--InteriorSeparator--
25
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
How does Slater's condition apply to the C-SVM optimization problem (P')?
--InteriorSeparator--
It is satisfied when there exists w ∈ Rd, w0 ∈ R, and ξ ∈ Rm such that (w * xi + w0)yi - 1 + ξi > 0 and ξi > 0 for all i.
--InteriorSeparator--
hard
--InteriorSeparator--
26
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the Lagrangian of the C-SVM problem, what do the Lagrange multipliers correspond to?
--InteriorSeparator--
αi >= 0 correspond to the constraints (w * xi + w0)yi >= 1 - ξi, and βi >= 0 correspond to the constraints ξi >= 0.
--InteriorSeparator--
medium
--InteriorSeparator--
27
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the main difference between the dual form (D') for C-SVM and the dual form (D) for hard-margin SVM?
--InteriorSeparator--
C-SVM has an additional constraint, αi <= C, which limits the importance of any single training example in determining the optimal separator.
--InteriorSeparator--
hard
--InteriorSeparator--
30
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
In C-SVM, how can w0 be obtained from the relationships derived?
--InteriorSeparator--
(right) w0 = yi(1 - ξi) - w * xi, with ξi = 0 if αi < C
(wrong) w0 = w * xi - yi
(wrong) w0 is independent of support vectors
(wrong) w0 = yi - w * xi
--InteriorSeparator--
hard
--InteriorSeparator--
30
--FlashCardSeparator--
}], role=model}, finishReason=STOP, avgLogprobs=-0.17565178185125763}]