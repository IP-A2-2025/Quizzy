***************Beginning Page***************
***************page number:1**************
1.
Support Vector Machlnes
(SVMs)
Contains:
Hard margin SVM: ex. 1, 2, 9,
Soft margin SVM (aka C-SVM): ex. 12, 20, 22, 23, 26,
Other SVM-like Optimization problems: ex. 29, 31, 33, 63, 64, 34, 66
from the 2023f version of the ML exercise book by L. Ciortuz et a1.

***************Ending Page***************

***************Beginning Page***************
***************page number:2**************
2.
The distance between a hiperplane and a point in Rd:
proving the formula
CMU, 2010 fall, Ziv Bar-Joseph, HW4, pr. 1.1

***************Ending Page***************


***************Beginning Page***************
***************page number:3**************
3.
What is the perpendicular distance of a point x0 to a hyperplane deﬁned by
wa + b I 0?
Let H be the hyperplane wa —|— b I 0 (which is the same as w - a; + b I O). We
want to ﬁnd the projection 113* of 11:0 on H. Given that the normal direction
vector of H is w, it follows that $* : x0+tw, for some real value t. Furthermore,
wTac* + b : O. Solving for t, we get:
t _ b —|— wao
— wTw '
Finally, the perpendicular distance of $0 to H is the distance between x0 and
513*:
\w-x-l-bI |w-:v+b\
d(:v0,x*) I \/ (x0 — 33*)T(£L'0 — 56*) I VwT'wt2 I — I —.
VwT w Hw||2

***************Ending Page***************

***************Beginning Page***************
***************page number:4**************
4.
From the maznimum margin principle t0 the
primal form 0f the SVM optimization problem
CMU, 2016 fall, N. Balcan, M. Gormley, HW4, pr. 1.1

***************Ending Page***************


***************Beginning Page***************
***************page number:5**************
5.
In this problem, you will derive SVM objective from the large margin prin-
ciple.
Suppose we have the following data D : (X, y), where X E Rdxm, the i-th
column a3, are the features of the i-th training sample and jg, is the label of
the i-th training sample, y € {—1,1}m.
We use the linear discriminant function
Q
For classiﬁcation, we classify a: into class Yx- -_ . .
—1 if f (cc) < 0 and into class 1 otherwise. l '-_ .
If the data is linearly separable, and f is . .
the target function, then yf(x) > 0. This '; . .
fact allows us to deﬁne o O l‘.
O O
'Y I MW) o W x

||w||2 O O O O
as the distance from x to the decision
boundary, i.e., the margin.

***************Ending Page***************

***************Beginning Page***************
***************page number:6**************
6.
We would like to make this margin *y as large as possible, i.e., maximize
the perpendicular distance to the closest point. Thus our objective function
becomes
max min M. (1)
w i:1,...,m lelQ
Show that (1) is equivalent to the following problem:
. 1 2
Hgn 5||wn2 <2)
such that yZ-(w - xi) Z 1, for 2': 1,. . .,m.

***************Ending Page***************


***************Beginning Page***************
***************page number:7**************
7.
Solution (in Romanian)
¢ w . x‘
max __r1nin M (3)
Vom demonstra echivaleniga dintre A w 1- “m H7111‘ .
problemele de optimizare (1) §i (2) a. 1' yi(w ' 331') > 0: pentru Z I 1» - - - ,m.
construind o succesiune de cateva
probleme de optimizare echiva- max 1 ‘ min yz- w . $2. (4)
lente, obiginute prin aplicarea unor w ku ZIL-"m
transformari succesive, pornind de a. i. yi(w - x2) > 0, pentru i I 1, . . . ,m.
la prima dintre cele doua prob-
leme date §i ajungand in ﬁnal la 1 , ‘ ‘ 5
cea de-a doua problema data in mSXHw||¢=riffi.I.1,mwa.$z ( )
enuni;. a. i. y,(w 413,) Z 1, pentru i I 1, . . . ,m.
Fie, a§adar, problemele de opti-
mizare din partea dreapta. max 1 (6)
w \Wll
a. i. y,(w - 33,) Z 1, pentru 2' I 1, . . . ,m.

***************Ending Page***************

***************Beginning Page***************
***************page number:8**************
8.
o Se observé c5 problema de optimizare (3) diferé de problema ini§ia15 (1) prin
introducerea unor restricgii liniare. Mai mult, aceste restrictii corespund
hiperplanelor care sunt separatori liniari pentru muly'imea de antrenament
datéi (care este, intr-adevér, separabiléi liniar). A§adar, aceste restrichi nu
schimbéi cu nimic solu§ia problemei date inigial.“
o Problema de optimizare (4) a fost 0b§inut5 din problema (3) modiﬁcénd doar
1 .
functla oblectlv: W a fost scos 1n fata operatorulul m1n¢:1,...,m ﬁlndca w nu
w
depinde de i. (Observaigi c5 expresia care urmeazé acestui operator depinde
de w, dar acolo acest w este ﬁxat; acolo variazéi doar x1.)
Pentru un separator llnlar oarecare a1 mu1§1m11 de antrenament, expres1a mlnizlpu,m W are 0 valoare strlct
'11]
. x.
pozitivé. Pentru hiperplanele care nu separéi mulgimea de antrenament, expresia mini-:1?“m %(||Z) are valoare
'11)
negativéi sau O.

***************Ending Page***************


***************Beginning Page***************
***************page number:9**************
o Problema de optimizare (5) a fost obtinuté din problema (4) schimbénd in restricgii 9.
relatia > O cu Z 1. In sine, aceastﬁ modiﬁcare restrénge multimea acelor valori ale lui
w peste care se aplicéi operatorul maxw.
Sé consideréim insé un w’ arbitrar care este eliminat la trecerea de la forma (4) 1a forma
(5). Notéim *y’ : mini-:1,___7myZ-w’ 10¢; §tim c5 'y’ € (0,1).
V
f (111‘)
Rezulté c5
Z 'L
yi—/:y¢—l-a:i21pentru1,...,m. ¢ '
'Y V ' '
/ Q
// not. w 0 0 '- 0
Agadar, w I —/ satlsface restrlcignle problemel (5). '
f)’ 0<Y’<1 . 0
In plus, O O
O O , 5! x

1 1 , _ 1 _ ,, 1 . , O O w w

||w~|| _ Hw'u” §1 11w~11 1,2111%wa '1'” Hw’\| #111,11ng O O O
W W
1 'y’

Prin urmare, putem spune 05 rolul lui w’ in relagia (4) este jucat de w” in relagia (5). In
consecingé, la trecerea de la 0 formii la cealaltii optimul riiméne acelagi.a

a Din punct de vedere geometric, trecerea de 1a (4) 1a (5) corespunde inmulgirii cu 0 constants} pozitivé (supra-
unitaré) a ecuaigiilor acelor separatori liniari [ai muligimii de antrenarnent] pentru care minimul distangelor geometrice
pénéi la instangele de antrenament este strict ma'i mic decét 1, astfel incét in urma inmulgirii aceastéi distangéi minimé
s51 deviné 1.

***************Ending Page***************

***************Beginning Page***************
***************page number:10**************
o Problema de optimizare (6) a fost obtinuté din problema (5) renungénd in funcigia 10-
obiectiv la minizlwm yi w - xi. Aceasta revine de fapt la a renuntja la acele valori ale lui w
pentru care IrlinZ-I1,___,m yiw - xi este strict mai mare decét 1. (Am vézut mai sus czii existii
valori ale lui w (§i anume, w”) pentru care minimul respectiv este chiar 1.)
u I v u not. .
Sa c0n51deram un w'” cu proprletatea 7”’ : 11(11117;:1W,m yi w’” - x2- > 1.
W
f (311')
Rezulté c551 I”
. w . .
‘mm yZ-T-xizl '
z:1,...,m 1/ . .

. will .
0 A ILrU — .
§1, notand w _ 7, vom avea. .

v v"’>1 . .
O O
l/l
1 . iv _ 1 _ 3/ _ 1 - /// O O m x

TZmln yZUJ -$Z—T—T—Tm1n wa ‘LUZ. O W _
llw ll 1:1,...,m llw H llw H 11w H 1:17---7m O W”

V _,—/ O O O

1 ,ylll
Prin urmare, [ca §i mai sus,] putem spune céi rolul lui 10”’ in relaigia (5) este jucat de w“)
in relaigia (6). In consecinigé, nu se modiﬁcé optimul dacéi se renuntéi [§i] la ace§ti w”’.a

a Din punct de vedere geometric, trecerea de la (5) la (6) corespunde inmulgirii cu 0 constanté pozitivé (sub-unitaré)

a ecuagiilor acelor separatori liniari [a1 mulgimii de antrenarnent] pentru care minimul distangelor geometrice péné la
instangele de antrenament este strict mai mare deceit 1, astfel incét in urma inmulgirii aceastéi distangé minimé s51
deviné 1.

***************Ending Page***************


***************Beginning Page***************
***************page number:11**************
11.
o Se constata imediat ca problema (6) este echivalenta cu problema de opti-
mizare SVM care a fost data in enunt (2).
Forma problemei de optimizare SVM ne
spune ca separatorul optimal se alege
dintre acei separatori w - x ai multimii
de antrenament care au exact valoarea 1 ,
pentru mini-21W,m yZ-w - sci; alegerea se face 0 '
maximizand 1/HwHa adica distanta geo- ‘\\ 1/”w” . .
metrica de la separat0r(i) pana la cele mai .
apropiate instante de antrenament. Intu- \ 0
itiv, maximizarea aceasta va implica fap- \\\ \ o '
tul ca distantele de la separatorul optimal O O\\
pana la toate instantele de antrenament O O O w x
cele mai apropiate (adica, "vectom'i-suport, O O O\
cei pozitivi §i respectiv cei negativi) vor \\\ \
ﬁ 1/||wH. (in ﬁgura alaturata, in care am \\\
pus in evidenta acest fapt, vectorii-suport \
sunt incercuiti.)

***************Ending Page***************

***************Beginning Page***************
***************page number:12**************
12.
The SVlVI optimization problem — the primal form;
getting the dual form,
the relationship between the primal and the dual solutions,
and the prediction rule
CMU, 2010 fall, Ziv Bar-Joseph, HW4, pr. 1.3-5
[Solution augmented by Liviu Ciortuz]

***************Ending Page***************


***************Beginning Page***************
***************page number:13**************
13.
geometric

margin
maximal @ O vectors
margin

o

o O‘~~.‘~~.
o O o NKDOC) = 1
Doc) = -1 0 Wééﬁﬁlzzaémg

***************Ending Page***************

***************Beginning Page***************
***************page number:14**************
14.
[In Romanian]
Se consideré instantjele x1, . . . ,xm E Rd §i etichetele correspunzétoare
yl, . . . ,ym € {-1, 1}. Problema SVM cu margine “hard” — termen care desem-
neazé cazul in care instanigele (51:1,y1), . . . , (Lumyn) se presupune c5 sunt liniar
separabile — este o problemd de optimizare convewd’, exprimatfi sub forma
primald astfel:
' 1|| ||2
mlnwﬂwO 2 w (P)
a. i. (w-st-+w0)yi Z 1, pentruz': 1,...,m,

unde w € Rd §i wO € R.
in urma rezolvérii acestei probleme se va ob§ine un model liniar, de forma
y(a:) I w - x + wO, ce va servi ulterior pentru clasiﬁcare, conform funcgiei de
decizie sign(y(a:)).

***************Ending Page***************


***************Beginning Page***************
***************page number:15**************
15.

La curs am prezentat metoda multiplicatom'lo'r Lagrange, care ne permite in
anumite condiigii sii rezolviim probleme de optimizare 0017/06an cu 'restricjii
de asemenea conveme — observaij'i c5 (P) este 0 astfel de problemé —,
transpunénd aceste probleme intr-o formé mai convenabilii numité forma
duald.
Pentru inceput, vom deﬁni 0 altii functie, numitéi lagrangeanul generalizat,
care combiné funcgia obiectiv din (P) cu expresiile care intervin in partea
sténgfi a restrichilor:

d f 1 m

6 .

LP(w,w0,O¢) I §||wH2 — 204M”) ' 5%‘ + w0)yi — 1),
i=1

unde 04¢ Z O pentru 2' : 1,m sunt aga-numitji multiplicatori Lagrange sau
variabilele duale. Variabilele primale sunt w §i wO.

***************Ending Page***************

***************Beginning Page***************
***************page number:16**************
16.
Observa§ie (1)
Este imediat c5 pentru problema (P1) este satisféicutéi asa-numita conditie a
lui Slater (vezi Learning with Kernels, B. Schiilkopf, A. Smola, MIT Press,
2002, pag 167):

Elw E Rd §i wO E R astfel incét (w - $1- + 1110)?” — 1 > O, pentru 2' I 1, . . . ,m. (7)
intr-adevér, faptul céi instantele (x1,y1),.. . , (mmyn) sunt liniar separabile im-
plicii imediat satisfacerea condiigiei de mai sus.
in consecinté, forma primalii (P) §i forma dualé (D) a problemei SVM —
aceasta din urmé va ﬁ 0b§inutéi la rezolvarea punctului b — vor avea aceeasi
valoare optimfi pentru funcigiile obiectiv respective. In notaigia consacraté
pentru metoda lui Lagrange, acest fapt se exprimé astfel: d* I 10*. Aceasté
egalitate se numeste proprietatea de dualitate tare.

***************Ending Page***************


***************Beginning Page***************
***************page number:17**************
17.
a. Calculénd derivatele pargiale ale funcigiei L P in raport cu variabilele primale
w §i wO, aréitagi c5 intre valorile 2D, @170 §i 64 pentru care aceste derivate par§iale
se anuleazéi existé rela§iilez
m
w I Z mast-w, (8)
1:1
m
i=1
De asemenea, arétaigi (:5 din condijia de complementaritate Karush-Kuhn-
Tucker ( KK T)
54i((w-33¢+1I)0)yi—1):0 pentrui:1,...,m. (10)
se poate deduce rela§iaz
zDO : yz- — 2T) - xi pentru orice 2' astfel incét 0-41- > O. (11)

***************Ending Page***************

***************Beginning Page***************
***************page number:18**************
18.
Calculéim mai intéi derivatele partgiale ale functiei L P in raport cu w §i respec-
tiv 100:“
3 m
awLPUU, U10» 04) I w — 27;:1 aiwiyi
(9 m
(92120 LP(7~U> U10, 04) I — 21-21 041%-
Atunci cénd se atinge optimul funcgiei L P (considerénd argumentul siiu 04
(9
ﬁxat) aceste derivate parglale devm egale cu 0. D1n —LP(’U_) 1170 64) : 0 rezulta
7 8U) 7 a
c5
m
i=1
o o 8 _ _ _ o 0 u 0 m _
Similar, ngQu, wO, 04) I O impllca relatla 22-21 041% I O.
'L
a in notagia matricealé, considerénd w §i sci pentru i : 1, . . . ,m vectori-coloané, putem scrie lagrangeanul LP
astfel:
1 T m T
Lp(w,w0,a) : 5w w — 2041((11) £131 + w0)yz- — 1).
1:1
Pentru derivarea lui L p in raport cu vectorul w, se folosesc regulile (5a) §i (5b) din documentul M at'm'x Identities de
Sam Roweis (New York University, June 1999).
Revenind 1a formula ini§ial€x, care folose§te notatia vectorialé §i produsul scalar din Rd, se poate constata cé intr-un
astfel de caz (simplul), regulile de derivare sunt similare cu cele din R.

***************Ending Page***************


***************Beginning Page***************
***************page number:19**************
19.
Apoi, din conditia de complementaritate KKT, care se expriméi sub forma
(ﬁzz-[(w-xz- —2I)O)yi — 1] : O pentru 71: 1,...,m
rezulté c5 pentru orice 2' € {1, . . . ,m} cu 072- > 0 avem (1T) - 31:1- + {Twyi — 1 : 0.
Aceastéi relatie este echivalentéi cu w - xi + 2170 : yi ﬁindcéi yi € {-1, 1}. Din
aceastéi ultiméi egalitate rezultéi
11-)0 I yz' — ’U_) ' $1‘.
Observatie:
Dacé 647; : O pentru i = 1,m, din relatia 1T; : 2:11 @iyiwi rezulté. 05 1T1 : O. in consecinté, functia
f(a:) I 'J) - a: + QDO care d5 ecuatia separatorului optimal (f(a:) I O) nu va avea putere de discriminare
intre instantele pozitive §i instantele negative (indiferent de valoarea atribuité. lui 1170, care este 0
constanté).
De fapt, atunci cénd s-a introdus problema SVM ca 0 problemé de optimizare a marginii / distantei
1/||w||, s-a considerat in mod implicit c5 se cautéi solutii w 73 O.
Agadar, in cazul in care in urma rezolvérii problemei primale, respectiv a celei duale — urmaté in
ultimul caz de aplicarea relatiilor de legéturé intre cele douéi tipuri / seturi de solutii — obtinem
’U_) I O, céutarea lui LEO (valoarea optimé pentru wo) pur §i simplu nu are sens.

***************Ending Page***************

***************Beginning Page***************
***************page number:20**************
20.

b. Calculaigi funcgia L D (04) care se obtine din expresia lagrangeanului gener-
alizat Lp(w,w0,a) substituind variabila w cu 2:11 almiyi §i folosind egalitatea
2211 ozZ-yz- I 0, conform relaigiilor (8) §i (9) de la punctul precedent.
Substituind w I 2:11 aixZ-yl- in expresia lui LP §i ginénd cont c5 2:11 aiyi I 0,
vom 0b§inez

1 m m

LBW) I 5 Zaiaij-iji '11?" — ZaiZKCijjxj ' 5'11" + wom — 1]
1,3‘ 1:1 3:1
m 1
I: m

***************Ending Page***************


***************Beginning Page***************
***************page number:21**************
21.
Observagie (2)

Este evident acum c5 problemei (P) ii poate ﬁ asociatéi urméitoarea ,forméi
(numitéi ,,dual§i“):

maxa L D(a)

a. i. 041-20, pentruz':1,...,m (D)

2:11 aiyi : 0
in care restrictiz'le sunt mult mai simple decét erau in forma primaléi (P).
Este de reginut faptul c5 relatiile (8) §i (11) de la punctul a constituie ,legétura
dintre solugia / solugiile problemei (D) §i solugia problemei (P).

***************Ending Page***************

***************Beginning Page***************
***************page number:22**************
22.
c. Dacii se d5 0 instanigé noué (de test) :ztnew, cum vegi decide clasa ei?
Mai intéi vom calcula
f<$new) I 11-) ' mnew + 1170
m
I (Z Ozzyirm) wnew + yk — 15-51111; (13)

1:1
unde 64 este solutia problemei duale (D), iar "u? §i 150, solutiile problemei primale
(P) sunt calculate conform relaﬁilor (8) §i (11) de la punctul a.
Dupﬁ aceea, dacé f (mnew) Z O atunci mnew va ﬁ clasiﬁcat pozitiv, iar in caz
contrar va ﬁ clasiﬁcat negativ.

***************Ending Page***************


***************Beginning Page***************
***************page number:23**************
23.
Observa§ie (3)

Remarcam faptul ca atat in funcgia obiectiv a problemei de optimizare SVM

in forma duala (D) cat §i in functia f care servegte la clasiﬁcarea instangelor

noi, operaigiile care se executa asupra instangelor sunt doar de tip produs

scalar: a31- - asj §i respectiv x,- anew.

Acest fapt face posibila folosirea funcjiilor-nucleu in contextul SVM, ceea (:e

este convenabil atat din punctul de vedere a1 0b§inerii (eventuale) a separa-

bilita§ii, cat §i din punctul de vedere al executarii eﬁciente a calculelor.

***************Ending Page***************

***************Beginning Page***************
***************page number:24**************
24.
The C-SVM optimization problem — the primal form;
getting the dual form,
the relationship between the primal and the dual solutions,
and the prediction rule
CMU, 2012 spring, Ziv Bar-Joseph, HWS, pr. 3.2
[Solution augmented by Liviu Ciortuz]

***************Ending Page***************


***************Beginning Page***************
***************page number:25**************
25.
[In Romanian]
Antrenam 0 SVM pe un set de date de intrare {x2} cu 2' I 1, . . . ,n, considerate
impreuna cu setul de etichete asociate {yi}, cu yz- € {—1, 1}. Se presupune ca
aceste date sunt neseparabile liniar.
Obiecti'vul pe care ni-l propunem aici este sa maximizam marginea dar in
acelasi timp sa permitem ca, la ﬁnalul antrenarii, unele (in genere putine)
dintre datele de antrenament sa ﬁe clasiﬁcate eronat.
Asadar, vom considera problema de optimizare
. 1 2 C m
mmwm §||w|| + 21:1 :Z- ,
A . P
a.1. (w-xi+w0)yi21—§i,pentruz:1,...,m ( )
51- 2 O, pentruz': 1,...,m,
t. . v
unde 5 n; (51,“ . ,ﬁm), 1ar C > 0 este un parametru care controleaza compro-
misul (engl., trade-off) pe care urrnarirn sa-l facem intre marirnea margin/ii pe
de 0 parte,“ si penalizd'rile pentru ,,destindere “ (engl., slack penalty) reprezen-
tate prin variabilele £1 Z 0 pe de alta parte.
a Prin margine aici vom intelege distanta dintre hiperplanul de separare optimala deﬁnit de solutia (10,100) a
problemei (P') si oricare dintre instantele 95¢ pentru care yZ-(w - ZCZ' + wO) I 1. Aceasta distanta este egala cu 1/|\w|[.

***************Ending Page***************

***************Beginning Page***************
***************page number:26**************
26.
a. Veriﬁcatgi faptul c5 pentru problema (P’) este satisfﬁcuté conditia lui Slater.
Condi§ia lui Slater pentru problema (P') se formuleazé astfel:
3w e Rd,w0 e R §i g G Rm a. i. (w-xi+w0)yi—1+§i > 0 §i 51- > 0, pentru 1' z 1, . . . ,m.
Luénd w I O, wO I 0 §i é} I 2 (de fapt, este suﬁcient s5 consideriim £2- > 1)
pentru 2' : 1, . . . ,m), se constaté c5 aceasté condiigie se veriﬁcéi imediat.
in consecingéi, optimul problemei primale (P') va coincide cu optimul proble-
mei duale (vezi punctul d).

***************Ending Page***************


***************Beginning Page***************
***************page number:27**************
27.

b. Folosind variabile duale (adicé, multiplicatori Lagrange), scrieigi expresia
lagrangeanului generalizat care corespunde problemei (P'). Speciﬁcaﬁ pen-
tru ﬁecare multiplicator in parte care este restrictia care-i corespunde lui in
problema (P').
Lagrangeanul generalizat care corespunde problemei de optimizare (P') este:

1 m m m

LP(w7w0>€,047/3) I 511w||2 + 0251' — 204M”) ' 3% + 1001111‘ — 1 + £1‘) — 25%
1:1 1:1 2:1

Multiplicatorii 042- 2 0 corespund restrictgiilor (w - 50¢ +w0)yz- Z 1 — {2-, in vreme ce
multiplicatorii 6»; Z O corespund restricgiilor {1} Z O.
c. Scriegi condijiile de complementaritate KK T (Karush-Kuhn-Tucker) core-
spunzétoare problemei (P').

***************Ending Page***************

***************Beginning Page***************
***************page number:28**************
28.
d. Calculénd derivatele parQiale ale lagrangeanului generalizat L p(w, wO, § , a, 5)
in raport cu variabilele 10,100 §i respectiv é‘, arétati 05 forma dualé a problemei
(P') este:
m 1
maxa (21:1 041- — 5 Zij aiozij-yjati - 5133-)
a.i. OgaingentruiI1,...,m (DI)
221 Oliyi I 0-
Analizaigi deosebirile dintre (D') §i forma dualii a problemei SVM cu margine
“hard” (a se vedea deﬁniigia (D) de la CMU, 2010 fall, Ziv Bar-Joseph, HW4,
pr. 1.3-5.
Calculénd derivatele parigiale indicate in enun1;, vom avea:
8w i:1 i=1
le(w,w0,§,oz,ﬂ) I O (I) —Zm:0qy¢ I O (I) iaiyi I O
6100 . .
1:1 1:1
8
8—ng(21),1%,§,04,§) :0 (I) C—04i —5i :0@ai+ﬁi I C pentru 2' I 1,...,m.

***************Ending Page***************


***************Beginning Page***************
***************page number:29**************
29.
Substituind primele doué dintre aceste rezultate in expresia de deﬁniigie a lui L P vom
obtgine:
LD (05> 6)
6 .
I 5 201101j111j11-1j + 0251- 211(((Z@1Wj) 1+110)11_ 1 +51‘) — 26151
1,3‘ 1:1 1:1 1:1 1:1
1 m
I 5 Z 041041y1yj$1'$j + 0251 —
1,3‘ 1:1
m m m m
— Z 041041311ij1 ' $1 — wo Z 041y1+ Z 041— Z 041551 — Z 5151
1,3‘ 1:1 1:1 1:1 1:1
0
1 m m m
I —— 2041041y1y1931 - $1 + 0251+ 2011" — 2(0111- 51)§1
2 1,1 1:1 1:1 1:1 T
m 1
1.
I 20” — 5 Zaiajy1y1$1 ‘$1 11; LBW)-
1:1 1,1
Observati c5 la scrierea argumentelor lagrangeanului LD, am renuntjat in ﬁnal la B,
intrucét ﬁz- (pentru 1' I 1,. . . ,m) a fost eliminat in timpul efectuéirii calculului.

***************Ending Page***************

***************Beginning Page***************
***************page number:30**************
30.
rIinémd cont c5 6,- I C — 04¢ Z 0 implicii 041- $ C, rezulté imediat (:5 forma dualii
asociatéi problemei (P') este cea indicatéi in enun§.

De remarcat faptul 05 forma dualéi (D') pentru problema C-SVM (cu margine
“soft”) diferéi de forma dualé (D) pentru problema SVM cu margine “hard”
doar prin restrictia suplimentarﬁ 04¢ g C. Aceasta inseamnéi céi ,,imp0rtan1_;a“
care revine oricéirui exemplu (whyi) in determinarea separatorului optimal
devine limitatéi.
Facem aici mengiunea céi legétura dintre solutiile problemelor (P') §i (D') este
datii de relaigiile care au fost obiginute la punctele c §i d: mai intéi

m

1:1
iar apoi 100 se obtine din relatia (2D - 051- + 'U_)0)ZJZ' I 1 — 51 pentru un 2' € {1, . . . , m}
astfel incét 641- > O, agadar

1710 I —'u_1-;ci+ yi(1 — 51), cu 51 I 0 dacé in plus 071' < C. (15)

Aceasté ultimé egalitate este implicaté de rela§ia 041- + 52- I C dedusé mai sus
§i condi§ia de complementaritate KKT Bifz- I O.

***************Ending Page***************


***************Beginning Page***************
***************page number:31**************
31.
Observatle
Daca 641- I O pentru i I 1,—m, obtinem ’ll_) I O, ceea ce reprezinta o solutie inadmisibila.
Ramane de tratat cazul 'in care 364i I C §i pentru orice alt dj avem ﬁe dj I O ﬁe dj I C. Este de
notat mai intai faptul ca din relatia 2:21 aiyi I O va rezulta ca jumatate din vectorii-suport sunt
instante pozitive, ia_r restul (cealalta jlimatate) sunt instan'ge negative. Apoi,_ 643- I C > O irnplica
yj (1D — 009- +1120) I 1 — 53- §i 63- I O §i deci 53- Z O. Pe de alta parte, dj I O implica 59' I C §i deci 59- I O,
in consecinta,
251' I Z £1‘: Z (1—yi(117-$i—130)): Z (1—yiw'$i)
I |{i:6¢Z-IC}|— Z yiQD-miI|{iz6¢Z-IC}|—"IIJ- Z yiatq;
izéziIC izoiizc
. _ 1 _ _ . _ 1 _2
I |{2:oziIC'}|——w- Z: aiyiwiI|{z:o¢iIC}|——w
C . _ C
zzaiIC'
Aceasta ne arata ca optimul problemei primale (Pl) depinde doar de vi) (nu §i de 7120).
Notand in mod generic prin 56+ instan'gele pozitive (§i cu 5+ valoarea variabilei de ,,destindere‘
corespunzatoare), iar prin_x_ instantele negativ_e (§i, corespunzatog, £_), v0_m avea de satisfacut
restrictiile 15-513++1T20 Z 1—§+ §i112-:E_ +1110 g —1+§_. Tinand cont ca 5+ Z O §i §_ Z O, consideram ca
1
din punct de vedere practic se poate lua pentru 1170 valoarea —5(rnin13+ {u-J'a:+}+rnaxw_ {13~m_}). De
remarcat ca intr-o astfel de situatie, marginea va reprezenta distanta dintre separatorul optimal §i
cele mai departate instante pozitive / negative clasiﬁcate corect. Evident, aceasta este 0 situatie
(destul de) extrema in raport cu ideea cu care s-a plecat la drum 'in formalizarea clasiﬁcarii cu
margine maximala.

***************Ending Page***************

***************Beginning Page***************
***************page number:32**************
32.

e. Datii ﬁind 0 solutie a problemei duale (D'), cum identiﬁciim vectorii-
suport?
Fie 64 0 solugie a problemei (D'), iar 11) §i U20 stabiligi ca mai sus (vezi relagiile
(14) §i (15)). Vectorii-suport sunt instan§ele x1- pentru care 541- > O.
Mai sus (vezi rezolvarea de la punctul d, la ﬁnal) am arétat (:55 541- € (O, C) i
é}- : 0, deci y,(w - 90¢ +7110) : 1. Alternativ, pentru 64,- : C_rezulté 61- f C— 07¢ I 0,
deci yiQI) - 051' + 'JJO) g 1.“ Similar, pentru 072- : O :> 5%- : C :> 5i I O, deci
M117) ' 5131' + ‘ll-10)Z 1-
Observajie: Cele trei rela§ii deduse mai sus, rescrise sintetizat ca

541- e (0,0) iyAw-wZ-ero) : 1

@iijz/M-wwwo) s 1

641-:0iyAw-wwwo) 2 1
sunt folosite ca 0 conditie de oprire pentru algoritmul SMO, care rezolvé
in practicéi problema de optimizare cu margine “soft” (desemnatéi aici §i in
continuare prin C-SVM).

a Dacé O < £2 g 1, atunci instanga xi este situaté in interiorul marginii, iar dacé £1 > 1, instanga mi este clasiﬁcaté
eronat.

***************Ending Page***************


***************Beginning Page***************
***************page number:33**************
33.
f. Cum va ﬁ clasiﬁcatﬁi 0 instanté noué m’?
Péstrénd notatiile de mai sus, instanta de test m’ va ﬁ clasiﬁcatéi pozitiv dacé
1Z2 - :13’ —|— U10 Z O, §i negativ in caz contrar.

***************Ending Page***************

***************Beginning Page***************
***************page number:34**************
34.
SVM Without constraints,
but using instead the hinge loss function
CMU, 2008 fall, Eric Xing, HW2, pr. 1.2
[Solution augmented by Liviu Ciortuz]

***************Ending Page***************


***************Beginning Page***************
***************page number:35**************
35.
[In Romanian]
Consideréim m instange de antrenament {xi,yi}'Z’-’ll. Vii readucem aminte cii
problema SVM cu margine “soft” §i parametru de ,,destindere“ C > 0 poate
ﬁ formulaté ca 0 problemé de optimizare (pétraticéi) cu restric§iiz
' (1H Moi) <16)
mm — w -
w7w07€ 2 . Z
1:1
a. i. (winZ +w0)yi Z 1 —§Z-, pentru i I 1,...,m
5i Z 0, pentruz': 1,...,m
a. Demonstratgi c5 formularea de mai sus este echivalentﬁ cu 0 problemé de
optimizare (tot péitraticé) féiréi restricgii de forma:
m
min <||wH2+AZmaXﬂ —yZ-(w-a:7;+w0), 0)), (17)
“mm 1:1
unde A este un parametru real pozitiv ﬁxat.

***************Ending Page***************

***************Beginning Page***************
***************page number:36**************
36.
Solution (in Romanian)
a. Din restricgiile din forma primala a problemei C-SVM, avem
£1‘ Z 1—y¢(w-w¢+w0) $512 07
ceea ce echivaleaza cu £1‘ Z max(1 — yz(w - £131- —|— wo), O) pentru 2' I 17 . . . ,m.
Operatorul min din expresia functiei obiectiv a problemei C-SVM (16) implica
faptul ca 5;‘ din solutia optima a acestei probleme (111*, 106, 5*) va ﬁ setata chiar
la valoarea InaX(1 — yi(w - xi —|— wo), O).
Vom arata prin reducere la absurd ca pentru orice soluigie optima 10*, 108,8 a
problemei C-SVM (16), rezulta ca 10*, wb" este §i soluigie optima a noii probleme
de optimizare (17) daca luam A I 2C.
intr-adevar, daca ar exista 15,150 o soluigie optima a problemei (17) mai buna
decat w*,w$,a atunci ar insemna ca 711,150 §i 51- nét' maX(1 — yi(w - $1 —|— 100), 0)
ar ﬁ pentru problema C-SVM (16) o solutie mai buna decat solu§ie optima
w*,wf§,£*, ceea ce este absurd.
a ,,Mai bun“ se traduce prin: valoarea fungiei obiectiv [calculata pentru respectivul tuplu 112,200] este mai mica
decat...

***************Ending Page***************


***************Beginning Page***************
***************page number:37**************
37.
Vom ariita acum c5 luénd A I 20, orice solu§ie optiméi a noii probleme (17)
este — printr-o extensie naturalé, dupéi cum vegi vedea — solutie optiméi a
problemei C-SVM (16).
Noténd 51' : max(1 — yi(w - $1- +w0), 0), rezulté imediat c5 (2') 51' Z 0 §i (ii) funcgia
obiectiv Hw||2 —|— A2211 maX(1 — yi(w - an,- —|— wO), O) se rescrie ca ||wH2 —|— A2211 52-.
Mai departe, din (i) putem avea ﬁe fl- I O, ﬁe £7; > 0.
in primul caz, {Z- I O, avem 1 — yi(w - x1- + wO) g O, adicé ZZ' mg. yi(w - 501- + wO) Z 1.
in a1 doilea caz, £1 > O, sau echivalent zz- < 1, din 5i I 1 — yi(w - £132- + wo) rezultéi
yi(w - 331' -|- 100) I 1 — £5.
A§adar, in ambele situatii avem yi(w - sci + wO) Z 1 — $2‘-
Am arétat astfel cé orice solugie optimii w, 150 a problemei (17), augmentatii
cu g} nét' maX(1 — yi(w - 332- + wO), 0) satisface restricigiile problemei (16).
Ca §i mai sus, prin reducere la absurd se poate aréita 05 1117111075 este chiar
solu§ie optimé pentru problema (16).

***************Ending Page***************

***************Beginning Page***************
***************page number:38**************
38.

b. Exprimaigi valoarea noului parametru A in funcigie de parametrul de ,,des-
tindere“ C.
A I QC, conform rezolvéirii de la punctul a.
c. Cum apreciatji din punct de vedere ,,calitativ“ aceasté noué formulare a
problemei de optimizare C-SVM?
Forma nou-obginutéi pentru problema de optimizare C-SVM este caracterizatéi
de 2'. lipsa restrictiilor asupra variabilelor §i z'z'. de realizarea unui echilibru
(engl., trade-off) intre
— simplitate,“L reﬂectatéi de termenul || w H2;
— 0 buné capacitate de predic§ie / generalizare in cazul ne-separabilitéﬁi
liniare a datelor de antrenament, graii'ie termenului A2211 maX(1 — yi(w 1161 +
U70), 0).

a in raport cu algi clasiﬁcatori, de exemplu regelele neuronale artiﬁciale.

***************Ending Page***************


***************Beginning Page***************
***************page number:39**************
39.
Observagie importanté
Este imediat c5 problema de optimizare (17) este echivalentéi cu problema
m
min (@HwHZ + Zmaxﬂ — y7;(w - xi + wO), 0)), (18)
10,1110 1::1
v . v 1
daca se c0ns1dera parametrul (ﬁxat) 8 I X > O.
Comparémd problema de optimizare (18) cu problema de optimizare din
deﬁnitia regresiei logistice cu termen de regularizare L2, putem observa 0
mare similaritate.
Diferenga constéi (doar!) in functia de cost / pierdere folositéi: SVM folosegte
funcgia de cost hinge, deﬁnitii prin f(z) I maX(1—z, O), pe cénd regresia logisticii
folose§te functia de cost logisticii 1n(1 + e_Z).a
Pentru un cadru unitar de prezentare a acestor metode de invégare (foarte
diferite!), bazat pe minimizarea costurilor/pierderilor, v5 recomandiim s5
citi§i Supplemental Lecture notes, de John Duchi, de la Universitatea Stan-
ford.
“ 1n mod similar, regresia liniaré, folosegte ca fundgie de cost suma pétratelor erorilor, iar algoritmul AdaBoost
folosegte funcgia de cost [negativﬂexponengialﬁi e_z.

***************Ending Page***************

***************Beginning Page***************
***************page number:40**************
40.
The Sequential Minimal Optimization (SMO) algorithm:
Proofs for the update rules
Nello Cristianini, John Showe-Taylor,
An Introduction to Support Vector Machines,
Cambridge University Press, 2000, pp. 139-140
[adapted by Liviu Ciortuz]

***************Ending Page***************


***************Beginning Page***************
***************page number:41**************
41.
a. Using the standard notations for the C-SVM optimization problem (the
primal and dual forms), knowing that the SMO algorithm uses the coordinate
ascent optimization strategy, and assuming that the free variables at the
current iteration are a1 and a2,
prove that
C“gem, unclz'pped : Ckgld + y2(E2 — E1)
77
alien), unclz'pped : Ckgld + yl y2 (043M _ agew, unclipped)7
Where
m
w I 2%‘ Cm $1‘,
1:1
Eh» I w-$k+w0—yk for k € {1,2},
Hi
not. :f(a:k)
77 I —H$1 — $2M?

***************Ending Page***************

***************Beginning Page***************
***************page number:42**************
Solution 42-
We know that the dual form of the C-SVM optimization problem has the objective
1

function LBW) I 2:11 04¢ — i 2:11 23:1 yiyjoziajzri - 1139- and the constraints 2:11 yZ-oq I
0 and Ogoq £0 forz': 1,...,m.

m
By denoting vi : < Zyj 043- atj > ml- for z' : 17 2, it follows that (*)

3:3

W

w-(y1a1w1+y2a2w2)
L _ _l 2 2 _l 2 2 _ _ _
D(041>@2) — 041 + 042 2041971 2042932 y1y2 0410421131'5132 91041111 y2©¢2v2 + 60n8t1-
V
S
Since ylcvl —|— ygag I — Zj>2 yjaj, by multiplying this relation with yl — which belongs to
{-1,1} —, we will get
041 + yly2 6Y2 I —y1 '04--
Zya J
s J>2
_/—/
COTLStg
Therefore,
Ozgld + 8043M : COW/Stg : 0611610, unclipped + SCL/ge'w, unclipped. (19)
1:
n0 .: 'y

***************Ending Page***************


***************Beginning Page***************
***************page number:43**************
43.
By substituting 041 I y — 5042 into LD(041,042) we get:
1 1
LD(042) I y-soz2+042—5(7-5042)2x%—§0¢gxg—s('y—sa2)a2x1 -x2—y1(y—5042)211 —y2042112+const1.
In order to maximize LD(a2) we will ﬁrst compute its derivative w.r.t. 042, and then
equate it t0 O:
8L 04 1 1
ﬂ I —s + 1 + —2$('y — 8062)£C% — £04213 — sywl 462 + 2042361432 + ylsvl — ygvg
8042 2 2
I —s —|— 1 —|— (57 — 042)113%— 04233; — swan-1E2 —|— 2&2561 -w2 + ylsvl — ygvg
I —042($i +mg — 2$1'$2)— 5+ 1 +51% — 373131'x2 +91. 8 U1 — 92112
y1y2
: —042($1 — 332)2 — 5 + 1 + mi — 57$1'152 + Q2111 — @2112 : 0-
Therefore
- —s+1+s(952—x-at)+ (v —v)
anew, unclzpped : V 1 1 2 3J2 1 2
2 xi+atg—2331-x2
I y2(—y1 +y2+y1v(w%—$1-w2)+v1 —UQ) (20)
11161 — $2112

***************Ending Page***************

***************Beginning Page***************
***************page number:44**************
44.
Note
The relationships (*) imply that the expression "02-111 does not depend on 041 or
a2. However, if in the writing of w I 22 yiozixz- we consider 041 and a2 as being
a?” and respectively 043M, and if we denote f(m) nit ww-l-wo I 2311 yjajxj-w+w0,
then we can state the following
Lemma:
11961) — 1&2) I U1 — v2 + ywxl ' ($1 — $2) — y2042lll'1 — $2H2- (21)
Proof:
v1 — v2 I f($1)— 91041-1"? — 312042111 $2 — (f($2) — 311041111 4112 — 312042113)
I f(5131) — 11/1 041 mi — 1112042561162 — f($2) + y1 041 331 162 + 920421’;
V V
7—so¢2 7—SO‘2
I f(rr1) — f(w2) — ywwf + syl 042113? — y20¢2w1 ~1132 + ywm W2 — Syl 012581 mg + yzozzwg
V V
y2 y2
I f($1) — f($2) — y1vwi+ y2042$i — y20425131-w2 + yﬂivl ‘$2 — 312042981 ‘$2 + 9201295;
I f(5131) — f($2) — ywﬁvi — $1'w2)+ y2042($i — 2%‘1152 + 93%)
I f(11?1) — f($2) — 3/1’Y($i — 111'$2)+ y2a2l|$1 — $2H2-

***************Ending Page***************


***************Beginning Page***************
***************page number:45**************
45.
Using this Lemma, we can substitute 112 — 111 in the relationship (20), thus
getting
old 2
anew, unclipped _ y2(f($1) — yl _ f<$2) + yZ) + 052 H331 _ $2M
2 _ —
H5111 — $2‘?
_ old 92(E1 _ E2) _ old 312(E2 — E1)
Hm —$2H —H~”61 —III2H
o 0 l. d O I
Flnally, 1n order t0 deduce 041mm’ “nmppe , we W111 use the equallty
Oégld + SOdgld : 'Y : 06111610, unclipped _|_ sagew, unclipped'
So,
l' d l’ d l' d
051L611), unc zppe : 'Y _ sagew, unc zppe : agld + SOdgld _ sagew, unc lppe
_ old old new unclipped
— 041 + y1y2(042 — a2 ’ )

***************Ending Page***************

***************Beginning Page***************
***************page number:46**************
46.
b. Rememeber that 0 g aj g C for j E {1, 2}. At each iteration of the
SMO algorithm you have to calculate two bounds, L and H, so as to further
constrain a2: 0 g L g a2 g H g C.
Prove that (in the context of our problem) these bounds are expressed by the
following “clipped” relations:
o If yl #yg, L:max(0,a2—a1),H:min(C,C+a2—d1)
o If 3/1 : yg, L : max(0,a1 + 042 — C), H : min(a1 + a2, C)
Note: Therefore, the updating rules will be:
H if Cknew, unclz'pped > H
agew, clipped : agew, unclipped if L2S O£121,611), unclipped g H (22)
L if O‘new, unclz'pped < L
2
06111610, clipped I 'Y _ sagew, clipped : afld + 8045M _ 806721610’ clipped
I Ck€ld + y1y2(agld _ agew, clipped).

***************Ending Page***************


***************Beginning Page***************
***************page number:47**************
47.
Proof:
—C§v<0: ogng;
O('2 OL2
C C
y17£y22>041—042:'y:>042:041—"y V
C-Y
_Y/
Y 0 C+Y C (11 O Y C (11
0§7<C2 Cg'ngC:
(1.2 (1.2
C C
y1zygz>0¢1+0422v¢042:—041+v ‘
Y \\\
O Y C (11 0 _C+y C y (11
That leads t0 the stated constraints (written in blue 0n the previous slide).

***************Ending Page***************

***************Beginning Page***************
***************page number:48**************
48.
c. Prove the following complementarity constraints (KKT) for [stopping] the
SMO algorithm:
NOT [(ozi < C AND yiEi < —tol) OR (04¢ > O AND yiEi > tol)] for
i I 1, . . . ,m,
where tol is a (small) positive constant.

***************Ending Page***************


***************Beginning Page***************
***************page number:49**************
49.
Proof:
We will make use of the following equality: yZ-Ei : y¢(f(xz) — yi) : y,f(a:2) — 1.
Hi
Odi<CI ﬂmi) I>Q¢Ei20
04¢>01 :NyiEigO'
041:0 iyiﬂxﬂﬁl I>yiEiS0
Taking P1 mg (041' < C), Q1 mg. (ZhEi Z 0), P2 ng' (041' > 0), and q2 “gt (yiEi S 0), it
follows that
(P1 —> Q1) /\ (P2 —> Q2) E ﬁﬁ[(191 —> Q1) /\ (P2 —> Q2)l E ﬁlVPl —> Q1) V ﬁ(P2 e (12)] E
ﬁ[Vein V (11) V ﬁ(W92 V (12)] E ﬁl(P1 /\ W1) V (P2 /\ WM,

which leads t0 the stated constraint.

***************Ending Page***************

***************Beginning Page***************
***************page number:50**************
50.
Exemplifying the application of
the Sequential Minimal Optimization (SMO) algorithm
CMU, 2008 fall, Eric Xing, HW2, pr. 1.3
[Solution proposed by Liviu Ciortuz]

***************Ending Page***************


***************Beginning Page***************
***************page number:51**************
51.

Suppose we are given 4 data points in 2-d space: :51 I
(0,1),y1 I —1; $2 I (2.0), 1/2 I +1; 953 I (1,0), yg I +1; x
and $4 I (0, 2), y4 : —1. We will use these 4 data points 2 4
to train a soft-margin linear SVM.
Let 041, 042, 043, 044 be the Lagrange multipliers for :51, 1 x1
x2, 3:3, 11:4 respectively. And also let the regularization X3 X2
parameter C be 100. 0

O l 2
a. Write down the dual optimization formulation for this problem.
b. Suppose we initialize d1 I 5, 042 I 4, 043 I 8, d4 I 7. And we want to update
041 and d4 (keep d2 and 043 ﬁxed) in the ﬁrst iteration. Derive the update
equations for 041 and d4 (in terms of d2 and 043). What are the values for d1
and 044 after update?
c. Now ﬁx d1 and d4, derive the update equations for d2 and d3 (in terms of
041 and 044). What are the values for 042 and 043 after update‘?

***************Ending Page***************

***************Beginning Page***************
***************page number:52**************
52.
Solution (in Romanian)
a. Particularizénd forma dualéi a problemei de optimizare C-SVM
(vezi CMU, 2012 spring, Ziv Bar-Joseph, HWB, pr. 3.2) pentru
acest set de date, dupéi efectuarea tuturor produselor scalare x,- ~90]-
vom ob§ineza
1
maXa1,a2,a3,a4 041 + 042 + 043 + 044 — 5W? + 404% + 04% + 4042 + 4041044 + 4042043)
a.i. 0 g 04,- g 100, pentruz':1,...,4
—041+042+043—O£4:O
a Concret, 95% I avg I 1, mg I xi z 4, 951 4:4 I £192 - £193 I 2, iar restul produselor scl- -xj cu z’ 75 j au valoarea O.

***************Ending Page***************


***************Beginning Page***************
***************page number:53**************
53.
b. Facem observatia ca, la acest punct, exercitiul cere sa se execute doua
iteratii ale algoritmului SMO pe datele furnizate, fara a aplica criteriul de
selectie a variabilelor libere §i conditiile de oprire formulate de John Platt,
autorul acestui algoritm.
in continuare, vom da doua rezolvari.
Prima va ﬁ mai simpla. Ea va urma z'deea algoritmului SMO — care aplica
o metoda de optimizare numita cre§tere pe coordonate (engl., coordinate as-
cent) — fara a recurge efectiv la formulele stabilite de John Platt. In schimb,
vom proceda direct la optimizarea functiilor obiectiv determinate de alegerea
(impusa, conform enuntului) a celor doua perechi de variabile duale speciﬁ-
cate.
La a doua rezolvare, vom aplica direct formulele generale pentru ,,actu-
alizarea“ valorilor libere din algoritmul SMO. Facem observatia ca §i aceasta
rezolvare va ﬁ utila cititorului, pentru ca vom scoate in evidenta anumite de-
talii / modalitati de calcul care nu sunt chiar ,,imediate“ pentru cineva care
nu este inca obi§nuit cu algoritmul SMO.

***************Ending Page***************

***************Beginning Page***************
***************page number:54**************
. . 54.
Prlma solugle
z'. La prima iteratie, avern initial a1 I 5, 042 I 4, 043 I 8, 044 I 7, iar apoi se laséi ,,libere“
variabilele 041 §i 044. Datoritéi restrictjiei 221:1 y404, I 0 din forma dualé a problemei
de optimizare C-SVM (a se vedea (D') la CMU, 2012 spring, Ziv Bar-Joseph, HW3,
pr. 3.2), vorn avea urméitoarea relatgie de legéituréi dintre valorile variabilelor libere:
0471161” + 042m” I 042 + 043 I 12.
Din restricgia 04, Z 0 — dar §i datoritéi faptului c5 yl §i y4 au acela§i semn — va rezulta
05 valorile posibile (,,fezabile“) pentru 041 §i 044 vor ﬁ limitate la intervalul [0,12], inclus
in intervalul [0, C] I [0,100].
Inlocuind a2 I 4, 043 I 8 §i a4 I 12 — 041 in functjia obiectiv a problemei de optimizare de
la punctul a, vorn 0b§ine expresia func§iei pe care va trebui sii 0 maximizém la aceastﬁi
iteraigie:
not. 1 2 2 2
LD,1(041) I 24 — 5(041 + 4- 16 + 8 + 4(12 — 041) —|— 4-4-8 —|- 4041(12 — 041))
1 I ' .
I 24 - 5(042 - 48041 + 832) 8 I 5 5
Valoarea lui 041 pentru care se atinge optimul acestei functgii este g
notatéi cu 0471mm uncupped §i, evident, este 5 : 24. Aceastéi valoare se 5-’,
aﬂé in afara intervalului [0,12]. Este imediat 05 maximul func§iei 8
LD,1(041) pe intervalul [0, 12] se atinge in punctul 0471mm Clipped I 12. In ‘T I I I
- v - - new, unclipped _ new, clipped _ _30 40 0 10 2° 3°
consecmiga, 044 va prlml valoarea 044 _ 12 — 041 _ 0. 041

***************Ending Page***************


***************Beginning Page***************
***************page number:55**************
55.
ii. La a doua iteratie, vom avea 041 : 12 §i 044 : 0 ﬁxagi, iar 042 I 4 §i 043 : 8 liberi. Din
relaigia 2?:1 yiozi I O rezulté
0/2”“ + 022,161” I 041 + 044 : 12.
Ca §i mai sus, intervalul in care vor ﬁ permise noile valori ale variabilelor 042 §i 043 este
[0,12]. Functia obiectiv din problema de optimizare convexéi devine:
LD72(022) :I 24 - 5(122 + 40¢; + (12 - 042V + 4 - 02 + 4 - 12 - 0 + 4022(12 — 022))
1 1
I —§a§ - 12022 — 120 I Em; + 24022 + 240)
Maximul global a1 acestei func§ii se atinge in punctul é‘ I
new, unclipped _ 24 _ . v A , O | |
042 _ —3 _ —12. Acest punct se Sltueaza 1n exterlorul N 5|,» I I I
intervalului de fezabilitate [0,12]. Maximul functiei LD,2(042) pe g g I I I
intervalul [0, 12] se atinge in punctul 0236"’; CIIpped I O. in consecinlﬁi, 8| I I I
w, u cli d _ new, cli ed _ I I I
age n ppe — 12_O‘2 pp —12' -3o -10 o 1o 20 so
Ol2

***************Ending Page***************

***************Beginning Page***************
***************page number:56**************
56.
A doua solugie
Formulele date de John Platt pentru actualizarea variabilei libere aj (la 0
iteratie oarecare a algoritmului SMO) sunt:
0421611), uncl'bpped : 04¢ + yi(Ei _ Ej)
77
H dacéi 062L611), unclipped > H
0421610, clipped : 0416111, unclz'pped dacﬁ L S 042L811), unclipped S H
L dacé Olgzew, unclipped < L
unde
Ekzw-zvk+w0—yk
4
w I Z 311041561‘,
i=1
2
n:— ||mi—a:j ll
L I max“), 041- — 049-) §i H I min(C, C —|— 041- — 043-) dacﬁ yi- 75 yj
L : maX(O, 04¢ —|— 049- — C) §i H : min(C, 042- + 043-) dacéi yi : yj.

***************Ending Page***************


***************Beginning Page***************
***************page number:57**************
57.
i. La prima iteragie, a1 I 5, 042 I 4, 043 I 8, 044 I 7, iar 77 I — H m1 — x4112: —1.
Féiré a face deocamdaté calculele, explicitiim erorile E1 I f(sc1) — yl I w - $1 + wO — yl §i
E4 I f(x4) — y4 I 10-5134 —l- wO — y4, deci rezulté E1 — E4 I w - (£131 — x4).
Din relagia w I 221:1 yiozl-xi, vom avea:
w I —041911 + 04sz + 0135183 — 014334
0 2 1 O 16
— —5111+4101+8101-7121—1—191
de unde rezulté c5 E1 — E4 I w - (x1 — x4) I (16,—19)- (O, —1) I 19 §i vom putea calcula
- E — E
agww, unclzpped : 041 + y1< 1 4) : 5 + 19 I 24
77
Acum veriﬁciim dacé 04711610’ “Whipped este in intervalul de ,,fezabilitate“: deoarece yl I y4,
vom avea L I max(0, 041 + 044 — 100) I O, pentru c5 041 + 014 I 12. Similar, H I min(100, 12) I
12.
intrucét 041m“ uncupped > H I 12, vom avea 04711611)’ Clipped I H I 12 §i, in consecinté,
CB26111, clipped : 12 _ avlzew, clipped : 0

***************Ending Page***************

***************Beginning Page***************
***************page number:58**************
58.
ii. La a doua iteraigie, a1 I 12, 042 I 4, 043 I 8, 044 I O §i agew+oz§few I 042 +013 I a1 +044 I 12.
De asemenea, 77 I — H x2—x3 HQI —1 §i E2 I f(x2)—y2 I w-x3+w0—y2, iar E3 I f(x3)—y3 I
w - x3 + wO — yg, deci E2 — E3 I w - (x2 — 51:3). Calculéim w astfel:
w I —6Y1151 + 042932 + 043$‘; — 044M
0 2 1 O 16
— —12111+4l@1+8l@1-0121—l121
deci E2 — E3 I (16,—12)- (1,0) I 16. A§adar,
- E —E
agew, unclzpped : 042 + y2< 2 3) : 4 _ 16 : _12
77
Deoarece yg I yg, vom avea L I max(0,a2 + 043 — C) I 0 §i H I min(C,a2 + 043) I 12. in
consecintgé, 043w’ uncapped I —12 < L I 0, deci in ﬁnal vom avea agew’ Clipped I L I O §i
agew, clipped : 12 _ agew, clipped : 12
Se remarcﬁ faptul c5 am regﬁsit rezultatele de la prima solu§ie.

***************Ending Page***************


***************Beginning Page***************
***************page number:59**************
59.
Observatie
Calculénd valoarea functiei obiectiv LD(a), folosind mai intéi val-
orile initiale ale parametrilor 047;, apoi valorile rezultate la ﬁecare
din cele doué iteratii, obtinem valorile: —268.5, —258, —129. A§a
cum era de a§teptat, aceste numere sunt in ordine crescétoare.
Dacé am ﬁ calculat §i valorile parametrului wO care apare in forma
primalii a problemei de optimizare date, precum §i valorile vari-
abilelor de ,,destindere“ 52-, am ﬁ putut calcula §i valorile functiei
1

obiectiv 5 H w HQ +C 2% 51-. Aceste valori trebuie s5 ﬁe in ordine de-
screscétoare §i mai mari decét valorile determinate pentru functia
LD(a) mai sus.

***************Ending Page***************

***************Beginning Page***************
***************page number:60**************
60.
SVM with RBF kernel:
sufficient conditions for getting O training error
Stanford, 2007 fall, Andrew Ng, HWZ, pr. 3

***************Ending Page***************


***************Beginning Page***************
***************page number:61**************
61.
[In Romanian]

Consideram 0 ma§ina cu vectori-suport care folose§te nucleul de tip gaus-
sian (RBF) K(a:,z) I eXp(— || 50 — z ||2 /’7'2), unde am notat cu eXp() funcjgia
exponengiala. Parametrul 7' determina marimea deschiderii ,,clop0tului“
gaussian.
La punctele a §i b de mai jos v5 vom ghida pas cu pas ca sa demonstragi
urmatoarea proprietate:

in ipoteza ca oricare doua instanii'e [anZ §i ZEj] din setul de date de

antrenamentnu sunt distincte, se poate ﬁxa 0 valoare a parametrului

'7' astfel incat eroarea la antrenare produsa de aceasta SVM sa ﬁe

zero.
La punctul c se va arata ca aceasta proprietate nu este valabila §i in cazul
folosirii clasiﬁcatorului C-SVM.

***************Ending Page***************

***************Beginning Page***************
***************page number:62**************
62.

a. Presupunern ca setul de date de antrenament {($1,y1),...,(a:m,ym)} este
alcatuit din puncte care sunt separate unele de altele de 0 distanta de cel
putin a, adica || :cj — xi HZ a pentru orice 2' 75 j.“
V5 readucem aminte ca functia de decizie invatata de catre SVM cu functie-
nucleu K se poate scrie sub forma:

m

m) z Z @iyZ-Km, as) + wO, (23)

1:1

unde a1,...,am € R+, wO este termenul liber/bias-ul din forma primala a
. . . . d .
problemel de optlmlzare [C-]SVM, 1ar K(:1:,-,:1:) if @(5131) - @(x), unde (I) este
,,maparea“ corespunzatoare functiei-nucleu K.
Gasiti valori pentru 041, . . . ,am, wO, precum §i pentru parametrul gaussian 7',
astfel incat toate punctele 3:1- sa ﬁe corect clasiﬁcate de catre clasiﬁcatorul
819n(f(w))-
a Evident7 daca sci 75 atj pentru oricei 75 j §i, binein'geles, daca m este ﬁnit, atunci putern lua a I mini-7% H azj —$i ||.

***************Ending Page***************


***************Beginning Page***************
***************page number:63**************
63.

Observa§ie importantii
Aceasté formuléi presupunea acolo c5 az- sunt solutiile problemei SVM in forma
dualii. Insii aicz' E lucréim cu aceasté presupoziii'ie.
Practic, aici vom alege 04,-, wQ §i 7' astfel incét $5 rezulte c5 f (de aceasté
for-mi) determinéi separabilitate liniard’ in spatiul de ,,tréiséituri“ in care sunt
@(zcl),...,<I>(a3m), deci §i separabilitate (simplé, deci in general neliniaré) in
spagiul original (in care sunt instantgele 11:1, . . . ,asm).
Ulterior (la punctul b), folosind acelagi f, vom aréita cii problema SVM admite
cel pugin 0 solutie ,,fezabil51“ — deci, cf. condiigiei lui Slater §i 0 solutie optimd
— pentru forma primalé (§i, de fapt, §i pentru cea dualé, dar asta pur §i simplu
nu are relevanigé aici) §i, in consecinté, solu§ia optimé va satisface §i ea aceastéi
proprietate de separabilitate, care ne asigurfi 05 eroarea la antrenare este O.

***************Ending Page***************

***************Beginning Page***************
***************page number:64**************
64.

Sugestii:
1. Veriﬁca§i faptul c5, lucrénd cu yz- € {—1,+1}, predicigia fécuté pentru $2- de
citre sign(f(as)) va ﬁ corectéi dacé ‘ﬂu/cl) — yi] < 1. Altfel spus, veriﬁcati c5 are
loc implicalgia |f(a:,) — yd < 1 :> yzfQQ) > Of‘
2. Fixénd 042- : 1 pentru 2' I 1, . . . ,m §i 100 I O, giisiigi 0 valoare a lui 7' pentru
care inegalitatea |f(xZ-) — yl| < 1 55 ﬁe satisfécuté pentru z' : 1, . . . ,m.
Réspuns
Sunt imediate urméitoarele echivalenge:

|f($i)—yi\ < 1@—1 <f(5131')—3!i < 1<:>_1+yi <f<$i) < 1+yi-
Pentru yi : —1, partea dreaptéi a ultimei inegalitﬁti duble de mai sus devine
f(xz) < 0. Pentru yi : 1, partea sténgﬁ a aceleiagi inegalitéﬁ duble devine
f(x2) > O. A§adar, dacé inegalitatea |f(a3@) — yZ-I < 1 este adevéiraté, atunci
instanga atl- este corect clasiﬁcaté de ciitre fundgia sign( f (55))
Conform sugestie'i din enun§, vorn considera 041- : 1 pentru 2' I 17 . . . ,m §i wO I 0.

a Aici f poate ﬁ géndit 1a cazul general (f : Rd —> R), nu doar ca separator produs de clasiﬁcatorul SVM cu nucleu
RBF.

***************Ending Page***************


***************Beginning Page***************
***************page number:65**************
65.
Pentru un exemplu de antrenament oarecare (xi, yi), vom avea:
m m
\fm) —yZ-| I ‘2111mm —y¢‘ I \Zyjexp <— H wj — $1- ||2 H) — yi]
9:1 3:1
I \yi +211]- eXp (- || 111 w- n2 H) -yZ-\
#1‘
I ‘Ewe/WP || wj w ||2 W)‘
9751'
S Z |yjeXp (— H $1 — 11% ||2 #2)‘ I Z lyjleXP(— || 921 1%" ||2 /¢2)
3751‘ 3751'
I Zexp (— || xj —:c¢ ||2 /7'2)
j¢i
é 26Xp(—62/T2) I (m — 1) eXp(—€2/72)-
3751‘
Prima dintre inegalitéigile de mai sus este datoratii aplicérii repetate a ine-
galitéiigii triunghiului (Ia —|— b| g |a| + \bI), iar a doua inegalitate decurge din
presupunerea c5 ||xj — £13Z|| Z a pentru orice 2' 75 j.

***************Ending Page***************

***************Beginning Page***************
***************page number:66**************
66.
Agadar, pentru a avea |f($z) — yZI < 1 pentru 2' : 1,...,m este suﬁcient 35-1
alegem pe 7' astfel incét
(m — 1) GXp(—€2/T2) < 1,
sau, echivalentﬂ
5
7' < —.
\/1n(m — 1)
De exemplu, putem lua 7' I 5/\/1n m.
Rezumcind, am arétat péné acum céi existﬁ 0 instantiere pentru variabilele
duale (041- : 1) §i pentru variabila primalé wO (§i anume, wO I O), pentru care
functia f (an) I 2:11 aiyiK(xZ-, an) + wO separfi perfect exemplele de antrenament
date.
Punctele b §i c de mai jos vor analiza dacé solutiile optime produse de SVM
§i respectiv C-SVM pe acela§i set de antrenament vor avea §i ele aceasté
proprietate.
V5 reamintim c5 solutiile optime pentru problema de optimizare [C-]SVM
ewz'std, atét pentru forma primaléi cét §i pentru forma dualéi — §i ele sunt in
relatia 1D : 2:11 @iyilﬂxux) — dacéi, spre exemplu, este satisfiicuté conditia
lui Slater.
a Presupunénd m > 1.

***************Ending Page***************


***************Beginning Page***************
***************page number:67**************
67.
b. Presupunem ca rulam 0 SVM fara variabile de ,,destindere“ (engl., slack
variables) folosind pentru parametrul T valoarea pe care ati gasit-o la punctul
precedent.
Va obtine oare acest clasiﬁcator (in mod necesar) eroare de antrenare zero?
De ce da, sau de ce nu?
Raspuns
Datorita faptului ca f(a:) : 2:11 aZ-yiK(wZ-,x) + wO : 2:”:1 aiyi<l>(:c¢) - @(x) + wo,
rationamentul prin care am facut alegerea valorii parametrului 7' de la punctul
a este in sine 0 demonstratie a faptului ca multimea {@(atiﬂZT-ll, unde (I) este
maparea corespunzatoare nucleului RBF este liniar separabilii.
Vom arata ca putem pune in corespondenta functia f din proprietatea
de separabilitate liniara obtinuta in spatiul de ,,trasaturi“ (in care sunt
@(wl), . . . , @(xm)) cu 0 anumita pereche {I}, 620 care satisface conditia lui Slater
in spatiul de trasaturi (in care sunt @(w)1,. .. ,<I>(x)m).
Conditia lui Slater, relativa la problema de optimizare SVM este urmatoarea:
exista 0 solutie strict ,,fezabila“, adica 0 asignare pentru w’ si 106, astfel incat
restrictiile din problema primala SVM sunt satisfacute cu inegalitate stricta:
yi(w - @(xz) + wo) > 1 pentru i : 1, . . . ,m.

***************Ending Page***************

***************Beginning Page***************
***************page number:68**************
68.
Fie 2' € {1,...,m}, ﬁxat. Luénd 041 I 1, ..., am I 1, wO I O, f(:13) I
2211 aijgiK(xZ-,$) + wO §i 7' ca la punctul a, vom avea \f(xZ-) — yZI < 1, deci
yZ-f(a:@-) > O. Notém w : 27;, ajyj<1>(wj). in consecinté,
m m
yi(w"1’($1)+ 100) I 2W” ' <I>(:1;,-) I 31¢ 2 @jyj@($j) ' ‘1)(5'31') I Z112‘ ZajyjKCI/‘jaxﬂ
j:1 j:1
I yif($i) > 0-
A§adar,
m
y,(w - <I>(a2,) + wo) I y,- ZozjyjK(a2j,an-) > O pentru z' I 1, . . . ,m.
j:1
Evident, putem multiplica toti 04,- cu 0 constantii pozitivé astfel incét relatia
precedenté s51 deviné
m
inajyjK(xj,a:Z-) > 1 pentru 2' I 1,. . .,m.
j:1
A§adar, am giisit 0 solutie strict ,,fezabilé“ (w', wé) pentru problema noastré
de optimizare. Prin urmare, conditia lui Slater este indeplinitii.

***************Ending Page***************


***************Beginning Page***************
***************page number:69**************
69.
In concluzie, soluii'ia optimé (171,150) a acestei probleme va ﬁ intr-adevér gésitéi
de ciitre SVM cu nucleu RBF, in vreme ce separabilitatea liniaré a mulgimii
{@(xQH-ll din ,,spa§iul de tréséturi“ garanteazé c5 aceastéi solugie optimé pro-
duce eroare nuléi la antrenare.
c. Presupunem c5 antrenéim un C-SVM (adicé 0 SVM cu variabile de ,,des-
tindere“) pe datele speciﬁcate mai sus, folosind pentru parametrul '7' valoarea
pe care a§i ales-0 la punctul a, iar pentru parametrul C 0 valoare ﬁxatii in
mod arbitrar, dar pe care nu 0 cun0a§tem dinainte.
Va obtine oare acest clasiﬁcator (in mod necesar) eroare de antrenare zero?
De ce da, sau de ce nu?

***************Ending Page***************

***************Beginning Page***************
***************page number:70**************
70.
Rﬁspuns
Clasiﬁcatorul C-SVM cu nucleu RBF nu va obtine in mod neapﬁrat eroare
nulﬁ la antrenare pe setul de date considerat, chiar dacé asigniim parametrului
7' valoarea geisitéi la punctul a.
[in general, pent_ru problema de optimizare convexé C-SVM solutia optimii
obtinuté (15,1504) pentru 0 valoare ﬁxaté a parametrului de ,,destindere“
C nu produce in mod necesar eroare la antrenare 0, chiar dacéi datele de
antrenament sunt liniar separabile. Se poate $51 existe un alt triplet (w', 106,5’),
1
pentru care eroarea la antrenare rezultaté $5 ﬁe 0, dar pentru care 5 H w’ ||2
1 _ _
+035;- > 5 u w ||2 +03 e1
De earemplu, putem considera cazul extrem in care C I O. in acest caz,
1
functia obiectiv este §||w\|2 §i, evident, w I 0 este solutie [optimé] a problemei
de optimizare C-SVM, indiferent de alegerea valorii parametrului 7'. insé. nu
avem garantia c5 in aceste conditii eroarea la antrenare este 0.

***************Ending Page***************


***************Beginning Page***************
***************page number:71**************
71.
The RBF (Gaussian) Kernel:
Some interesting properties
MIT, 2009 fall, Tommy Jaakkola, HWZ, pr. 1

***************Ending Page***************

***************Beginning Page***************
***************page number:72**************
72.
We can write the radial basis kernel in the following form:
K(5U x’) I eXp —LHZU — x/H2
’ 202 7
where m and x’ belong to Rd, and 0 is a Width parameter specifying how
quickly the kernel vanishes as the points move further away from each other.
We will show that this kernel has some remarkable properties:
It can perfectly separate any ﬁnite set of distinct training points. Moreover,
this result holds for any positive ﬁnite value of 0.
[However, While the kernel Width does not affect Whether we’ll be able to per-
fectly separate the training points, it does affect generalization performance]

***************Ending Page***************


***************Beginning Page***************
***************page number:73**************
73.
Let’s proceed in stages.
We’ll ﬁrst show that the optimisation problem
. . . 1 2 .
minlmlze inH SlleGCt to yZ-w - Mani) : 1, . . . ,n
has a solution regardless of how we set the i1 training labels yi.
Here $(xi) is the feature vector (function actually) corresponding to the radial
basis kernel K.
Note: Our formulation here is a bit non-standard for two reasons:
1. We try to ﬁnd a solution Where all the points are support vectors.
2. We also omit the bias term since it is not needed for the result.

***************Ending Page***************

***************Beginning Page***************
***************page number:74**************
74.
a. Introduce Lagrange multipliers for the constraints [similarly to ﬁnding the
SVM solution] and show the form that the solution w* has to take, i.e. express
1D as a function of the Lagrange multipliers. (This should not involve lengthy
calculations.)
Notes:
2'. The Lagrange multipliers here are no longer constrained to be positive.
(Since you are trying to satisfy equality constraints, the Lagrange multipliers
can take any real value.)
ii. You can assume that w and gb(a:¢) are ﬁnite vectors for the purposes of
these calculations.
b. Put the resulting solution back into the classiﬁcation (margin) constraints
and express the result in terms of a linear combination of the radial basis
kernels.

***************Ending Page***************


***************Beginning Page***************
***************page number:75**************
Solution 75'
a. The Lagrangian for this optimization problem is:
1 n 1 n TL
ma) I 511012 — Zai<yiw-¢<w1>— 1) I 511012 — w- (Ea-WW) + Zai-
Z:1 1:1 1:1
Here each a,- is unconstrained, because we have equality constraints rather than in-
equality constraints. As usual, the dual optimization proble'rn is
max 9(a) : max min L(w, 04) .
Oé Oé U)
‘_/—/
not.: 9(a)
For a ﬁxed a, the expression L(w,a) is positively quadratic in w. We can obtain the
(9L
optimal w* from the ﬁrst-order condition % I 0:
w
TL
10* I Za§yj¢(xj).
3:1
For convenience, we will use the short-hand w* : @[yoa*]. Here o represents an element-
Wise product and (I) is a m >< n matrix, Where the ith column is ¢(:t,). (Of course, m I oo
for the RBF kernel.)

***************Ending Page***************

***************Beginning Page***************
***************page number:76**************
76.
b. Our constraints are equivalent to:
¢($1)T’LU : yi, 11: 1, . . . ,n.
Using matrix short-hand notation and substituting w* : (My o 04*], we obtain:
<I>Tw* I y
‘PTCNy ' 04*] I y
Kw ' 01*] I y,
Where K ﬁg" <I>T<I> denotes the kernel matrix (or, Gram matrix).

***************Ending Page***************


***************Beginning Page***************
***************page number:77**************
77.
c. Indicate brieﬂy how we can use the following Michelli theorem to show that
any n by n RBF kernel matrix Kij I K(xZ-,xj) for i,j I 1, . . . ,n is invertible.
Theorem (Michellz'): If p(t) is a monotonic function in t € [0,00), then the
matrix pZ-j : p(HxZ-—acj||) is invertible for any distinct set of points mhz' I 1, . . . ,n.
d. Based on the above results put together the argument to show that we
can indeed ﬁnd a solution where all the points are support vectors.

***************Ending Page***************

***************Beginning Page***************
***************page number:78**************
78.
c. Note that p(t) : eXp —2—2t lS a monotonlc functlon 1n t E [0,00). Usmg
0

the Michelli theorem, for any distinct set of points x¢,z' I 1,. ..,n, the matrix

1
K, with entries Ki,- : exp (—2—2w, — ijIZ), is invertible.

0
d. As we have a distinct set of points, K is invertible. Then the linear system
K[y o 04*] : y is feasible, and has a unique solution given by 04* : y o (If-1y).
Therefore, 10* : @[y o 04*] : <I>K_1y.

***************Ending Page***************


***************Beginning Page***************
***************page number:79**************
79.

e. Of course, the fact that we can in principle separate any set of training
examples does not mean that our classiﬁer does well (on the contrary). So,
why do we use the radial basis kernel? The reason has to do with margin that
we can attain by varying 0. Note that the effect of varying 0 on the margin is
not simple rescaling of the feature vectors. Indeed, for the radial basis kernel
we have

||<b(w)||2 I Ml") -¢(;1;) I KWW) I 1-
Let’s begin by setting 0 to a very small positive value. What is the margin
that we attain in response to any n distinct training points?
f. Provide a 1-dimensional example to show how the margin can be larger
than the answer to part e. You are free to set 0 and the points so as to
highlight how they might “contribute t0 each other’s margin”.

***************Ending Page***************

***************Beginning Page***************
***************page number:80**************
80.
e. As 0 —> O, the points become very far apart with respect to 0, and our
kernel matrix K —> I, the identity matrix. Because our constraints dictate
that K[y 0 04*] I y, then 04* —> 1, the all-ones vector. Therefore, ||w"‘||2 I
1
[y o 04*]TKLy 0 04*] —> yTIy I n, and we obtain a margin of \/: in the limit.
n

f. The simplest example to create is a set of 2 distinct points a: and as’, both

1
labeled +1. Denote [<3 I K(:13,a:’) I exp (—2—2||a2 — x’|2) . The kernel matrix can

0
be written as:

1 k:
K — l I. 1 l
Sl' th t K[l ] l'ld th lt' * 1 1 T d
ovm essem 004: 1e s esoulona: —— an
g y y k+1k+1
2 1 k 1
||w*||2 : a*TKa* I —. Therefore, the margin is — I UL. As long as
k + 1 Hw* H 2
x and at’ are distinct, we have that k > O, so the margin is always greater than
1

***************Ending Page***************


***************Beginning Page***************
***************page number:81**************
81.

Remark
As we take the 2 points arbitrarily close together (or alternatively, imagine
that 0 —> +00), then k —> 1, and we obtain a margin of 1.
Is 1 always the largest possible margin that we can obtain?
For the RBF kernel, one can think of the corresponding inﬁnite-dimensional
feature vectors qb(a:,~) as lying on the unit ball, as they are unit-normalized:
||gz5(x,-)||2 : K(a:,-,m,) : 1. So yes, the largest possible margin must be 1.
Intuitively, as a —> +00, kernels centered at distinct points gradually become
indistinguishable. In effect, all the feature vectors collapse onto each other
(to a single point) on the unit ball. As they do, the margin goes to 1 in the
limit.

***************Ending Page***************

***************Beginning Page***************
***************page number:82**************
82.
()ne-class (Max Margin) SVM,
the hard margin version
Stanford, 2007 fall, Andrew Ng, practice midterm, pr. 4

***************Ending Page***************


***************Beginning Page***************
***************page number:83**************
83.
[In Romanian]
Dat ﬁind un set de instange neetichetate 3
$1,...,a;m E Rd, un algoritm SVM de tip one- 15 '
class cauta sa identiﬁce (daca este posibil) o
directie w E Rd care separa in sens maximal I ' ‘ .
datele de originea sistemului de coordonate, ca l5 - '
in ﬁgura alaturata. ‘ * , ‘.1 ~
l I I +I + + I l
Mal pre01s, acest algorltm rezolva problema de , - * - '
optimizare (data in for-ma primala):1 In . , *
1 E‘ '
. 2 .
A - 'Mn' 'ﬁ'l' ' "I" 1*" "é' '1"? 'a
a.1. w-xZ-Zl,pentruz:1,...,m. J J J
Credit: Tommi Jaakkola, MIT,
O instanta noua (de test) va ﬁ etichetata cu —|— ML course, 2009 fall, lecture notes
V U A 5|
daca w - a; Z 1, s1 cu — 1n caz contrar.
La MIT, 2009 fall, Tommi Jaakkola, ML course, lecture notes 5 se da o alta varianta a problemei one-class SVM,
deﬁnita cu ajutorul sferei de incluziune minimald (engl., minimum enclosing ball, MEB). Pentru a putea distinge mai
usor cele doua versiuni una de cealaltzi7 vom numi varianta de aici Max M argz'n.

***************Ending Page***************

***************Beginning Page***************
***************page number:84**************
84.
Observatie: Un astfel de algoritm este util pentru detectia anomaliilor (engl.,
anomaly detection). in astfel de situatii, ni se da mai intai un set de date
care se considera ,,n0'r'male“. Apoi ni se cere sa decidem pentru alte instante
daca sunt (sau nu sunt) ,,an0malii“ (engl., outliers).
a. Scrieti forma duala corespunzatoare problemei de optimizare SVM one-
class de mai sus. Simpliﬁcati raspunsul cat mai mult posibil; w nu trebuie sa
apara in rezultatul ﬁnal. Veriﬁcati daca forma primala satisface conditia lui
Slater.
Putem veriﬁca de la bun inceput faptul ca problema de optimizare care a fost
data in enunt in forma primala satisface conditia lui Slater. Daca exista un
hiperplan care trece prin originea sisternului de coordonate §i ,,lasa“ toate
instantele m,- cu 2' : 1, . . . ,m de 0 aceea§i parte a sa, aceasta inseamna ca exista
w € Rd astfel incat w-aZZ- > O pentru i I 1, . . . ,m. intrucat m este ﬁnit, inmultind
acest w cu 0 anurnita constanta pozitiva obtinem w - at,- > 1 pentru 2' : 1,. . . ,m,
deci conditia lui Slater este satisfacuta.

***************Ending Page***************


***************Beginning Page***************
***************page number:85**************
85.
Lagrangeanul generalizat care corespunde problemei primale date este:
1 m
LP<UJ,O() : 5w - 201-20211 —w5132')
2:1
cu 022- 20 pentruz': 1,...,m.
Egalénd cu O derivata partialé a lui L P in raport cu w, 0b§inem w : 2:11 aim.
Substituind aceasté egalitate in expresia lui L p, vom avea:
1 m m m m
LBW) I i<2©¢2$2> ' (Zajxj) + 2042(1 — (Z 04.2%‘) ‘1132)
2:1 3:1 2:1 3:1
m 1 m m
2:1 2:1 3:1
A§adar, forma lui L D coincide cu cea de la problema SVM cu margine “hard”,
dar problema dualéi este in cazul de fatéi mai simpléi: pmaxazo L 13(02).

***************Ending Page***************

***************Beginning Page***************
***************page number:86**************
86.
b. Am putea ,,kerneliza“ algoritmul SVM one-class atét la antrenare cét §i la
testare? Adicéi: datéi ﬁind 0 functie-nucleu K, este posibil ca dupéi maparea
corespunzétoare, variabilele ac sii aparﬁ
— atfit in expresia lagrangeanului (LD) care reprezinté funcigia obiectiv a
formei duale ale problemei SVM one-class (varianta Maw Margin),
— cét §i in funcgia de decizie / clasiﬁcare pentru 0 instanté noué x’,
doar ca argumente ale functiei-nucleu K?
1n ce prive§te kernelizarea la antrenare, este imediat c5 rﬁspunsul este aﬁr-
mativ, deoarece in expresia lagrangeanului L D care a fost deduséi la punctul
precedent m1 §i scj apar doar ca [perechi de] factori in produsele scalare. Con-
cret, dupé ,,mapare“ folosind functgia <1> corespunzétoare nucleului K , vom
avea:
LBW) I 2%- — 5 226110111951) -<1><wj> I Zam- — 5 ZZQZ-(szKm-w
2:1 1:1 3:1 1:1 2:1 3:1
Pentru testare, riispunsul este de asemenea aﬁrmativ: datii ﬁind 0 instanlgii
de test at’, ea va ﬁ clasiﬁcatéi in functie de valoarea expresiei
o w - x’ : (2:21 041m) - m’ : 2:11 042-561- -:B’, in cazul in care nu se face mapare
o w - x’ : 2:11 04¢<I>(:IJZ-) - @(x') : 2:11 04,-K(a:Z-,a:’), cénd se face mapare.

***************Ending Page***************


***************Beginning Page***************
***************page number:87**************
. 87.
Observatle

Imaginile de mai jos ilustreazii rezultatul folosirii a douéi functii-nucleu de
tip RBF in conjunctie cu one-class SVM (varianta Maw Margin) pe setul de
date din enunt. Pentru rezultatul ilustrat in partea dreaptii, s-a lucrat cu 0
valoare [mai] micé pentru parametrul 02 din deﬁnitia nucleului RBF.

'3 a

25 ‘ 2:.

E I Q

15 . | | .5 I:

n5 us.

U u Q Q
Mu cla- | 1E- 2 25. a M": "ifs." i' ' i'é :3" ‘Ewi ' a

Credit: Tommi Jaakkola, MIT, ML course, 2009 fall, lecture notes 5.

***************Ending Page***************

***************Beginning Page***************
***************page number:88**************
88.

c. Concepeti un algoritm de tip SMQ“ care sa rezolve problema duala obtinuta
la punctul a. Ideea de baza a unui astfel de algoritm este ca la ﬁecare pas sa
produca solutia optima pe cea mai mica dintre toate submultimile posibile de
variabile. Dati formulele analitice (engl., in closed form) pentru actualizarea
variabilelor din aceasta submultime. Trebuie sa justiﬁcati / explicati de ce
este suﬁcient sa consideram simultan respectivul numar de variabile (engl.,
“at a time”) la ﬁecare pas.

intrucat in formularea data in enunt pentru problema one-class S VM nu se
folose§te termenul liber (engl., “bias”) wO, nu avem in forma duala a problemei
de optimizare 0 restrictie de tipul 227:1 yioq I 0 (cum a fost cazul la CMU,
2008 fall, Eric Xing, HW2, pr. 1.3). Agadar, vom folosi tot metoda cre§terii
pe coordonate (engl., coordinate ascent) ca in algoritmul clasic SMO, insa
vom alege la ﬁecare iteratie doar (Cate) 0 variabila Lagrange (047;).

Din expresia lagrangeanului dual LD(0¢) pe care l-am calculat la punctul a,
obtinem functia pe care trebuie s-o optimizam la iteratia curenta:

1
L(aZ-) I 04¢ + 2 04¢ — Z aiajzci 169' — 50412371‘ ~$i + const.
jii .77“
a Vezi CMU, 2008 fall, Eric Xing, HW2, pr. 1.3 gi (mai ales!) referintele bibliograﬁce indicate acolo.

***************Ending Page***************


***************Beginning Page***************
***************page number:89**************
89.
Punctul de maxim este dat de solugia derivatei de ordinul intéi a acestei
funcgii:
_ _ new, unclzpped _ 3752 J J Z

8——0 (I) 1—§ ajwj-zv¢—a¢:v¢-wi—0<i>ai ——.

04¢ . . 551' ' 33¢

9751

Iinénd cont de restricigia 042- 2 O, rezulté (:5 noua valoare pe care 0 atribuim

. . . l‘ d 1—2. .a-$-~x-
varlabllel alese este a?“ c We : max {0, %}-

’L Z

Mai rémém de speciﬁcat:
— criteriul de selecgie a variabilei ,,libere“; de preferin§5 aceasta se va face in
a§a fel incét $5 se 0b§inéi 0 cre§tere cét mai mare a valorii func§iei obiectiv de
la 0 iteratie la alta;
— criteriul de oprire a algoritmului; spre exemplu, atunci célnd cregterea
functiei obiectiv de la 0 iteratie la alta devine nesemniﬁcativii este inutil séi
mai executiim noi iteraigii.

***************Ending Page***************

***************Beginning Page***************
***************page number:90**************
90.
u-SVM
B. Schoelkopf, A. Smola, 2002

***************Ending Page***************


***************Beginning Page***************
***************page number:91**************
[In Romanian] 91-

Comentariu: Parametrul de destindere / regularizare C > 0, din forma
problemei SVM cu margine “soft” (introdus de catre Cortes si Vapnik, in
Support Vector Networks, 1995),“ permite realizarea unui compromis intre
doua obiective antagoniste: maximizarea marginiib si minimizarea erorii la
antrenare. La valori mari ale lui C rezulta un nivel scazut al sumei erorilor in
raport cu marginea (2211 é}, in notatia uzuala). Invers, la valori mici ale lui
C rezulta un nivel ridicat al sumei erorilor. Totusi, semniﬁcatia parametrului
C este prea putin intuitiva, iar valoarea sa nu poate ﬁ determinata a priori.
De aceea, in locul acestei variante de SVM cu margine “soft”, B. Scholkopf,
A. Smola, R. Williamson si P. Bartlett au propus in articlolul New Support
Vector Machinesc o abordare diferita, in care se foloseste un alt parametru
numeric, 1/, astfel incat daca m reprezinta numarul instantelor de antrena-
ment, atunci um va limita superior numarul de erori produse la antrenare.d
Se poate demonstra ca um este totodata o margine inferioara pentru numarul
de vectori-suport.e
Varianta aceasta este cunoscuta sub numele de u-SVM.

a Vezi CMU, 2012 spring, Ziv Bar-Joseph, HW3, pr. 3.2.

b Deﬁnita ca distanta de la hiperplanul de separare optimala w - a: + wo : 0 pana la vectorii-suport 51:7; pentru care

(w 41¢ + 1110):’;1 I 1-

C Publicat in revista Neural Computation, 12:1207-1245, 2000.

d See the explanation on next slide.

e Vezi rezolvarea punctului a de mai jos.

***************Ending Page***************

***************Beginning Page***************
***************page number:92**************
92.
[LCz]
La CMU, 2017 fall, Nina Balcan, HW4, pr. 4.Q12 s-a arétat (:5 in contextul
problemei de optimizare C-SVM numérul de erori comise la antrenare este
méirginit superior de céitre suma variabilelor de ,,destindere“ (21$).
Similar, pentru problema (P”) de mai jos se poate arfita imediat, analizénd
doar(!) forma restric§iilor, (:5 numérul de erori comise la antrenare este aici
1
mérginit superior de — 215i.
p
Prin urmare, dacéi impunem conditjia séi avem maximum um erori la antrenare,
aceasta implicé
1 1
umﬁ —Z§i<:>up§ —Z§}.
p i m i
Aceasta explicii forma functiei obiectiv din problema (P”) de mai jos.

***************Ending Page***************


***************Beginning Page***************
***************page number:93**************
93.
‘In-'1". i {I '--?-l*\ TIE--H'I-
)- . a .. _--"__.-'r'_ Ll‘!- _ .IIF i. - . 5:" ‘E 1- _
'1'5' :rr- ‘.1... I fir-h...‘ ll- 'f-ll-I'I-l . ‘fr-L‘.-
jl- ‘I I‘: i 1- ‘ ":1 I FIR-“Ir:
"l I Ill IJ ' I "I" .1’ . I L‘. J I
I ‘hut-'- l-IIIJI ‘Ill-‘r.-
Egure '19 Te}; prehlemﬁask: separate eimles tram disks} suhreqi using II'EluF elassiﬁmh'en,
with Parameter 1Iralues ranging ﬁ'em u = Ill {tap left]I tn 11' = 11-3 {hettcan right}. The larger
we make P, the mel-re paints are allewed te lie inside the margin [depleted by matted lines}.
Results areshewn tea-a Gaussian kernel, Hr. I“) = e:p{— ||.1' — .I'IIZ'}.
Credit: B. Schiilkopf, A. Smola, Learning with Kernels, MIT Press, 2002, pag 207.

***************Ending Page***************

***************Beginning Page***************
***************page number:94**************
94.
Problema de optimizare u-SVM are forma primala urmatoare:
1 1
. 2 m
2 m
a. i. yi(w-x¢+w0) 2,0—§¢, pentruz':1,...,m (P”)
£7; 20 pentruz': 1,...,m
p z 0.
De remarcat prezenlga variabilei suplimentare p, care va trebui sa ﬁe supusa
I I I I I I I t.
procesulul de optlmlzare la fel ca §1 varlabllele w, wO §1 <5 n; ($1,. . . ﬁrm)“
a. Derivalgi forma duala corespunzatoare problemei u-SVM. Simpliﬁcatgi rezul-
tatul cat mai mult posibil.
a Din forma restricgiilor liniare rezulta ca distanga de la separatorul optimal la vectorii-suport care nu vor ﬁ
clasiﬁcagi eronat in raport cu marginea i adica cei pentru care multiplicatorul Lagrange 04%- corespunzator va apargine
1
intervalului (0, —), conform problemei duale (D”) de mai jos — va ﬁ ||—p||.
m w

***************Ending Page***************


***************Beginning Page***************
***************page number:95**************
95.
Vom urma liniile ,,met0dologice“ care au fost folosite laCMU, 2010 fall, Ziv
Bar-Joseph, HW4, pr. 1.3-5 §i CMU, 2012 spring, Ziv Bar-Joseph, HW3, pr.
3.2. Mai intéi, este u§0r de veriﬁcat faptul cii problema de optimizare (P”)
satisface condigia lui Slater: luénd w : 0, wO : 0, ,0 I 0 §i £1 : 1, restricgiile
yi(w - 3:7; + wo) > p — 51' sunt indeplinite, pentru 2' I 1,. . . ,m. Prin urmare, vom
putea opta ca in loc s51 rezolvéim problema (P”), s51 rezolviim duala ei.
Apoi, lagrangeanul generalizat pentru problema (P”) este
L< g 36> 1n IF Ni:
w w a I — w —u — Z-
P 7 07 up) 7 7 2 p m 2.:1
— Z 041%(10'331' + U10) — p + 5i) — 25k}- — 5p,
1:1 1:1
unde 041', 51' §i 5 sunt multiplicatori Lagrange.
A . . . w I Z711 aiyZ-wz-
Calculand derlvatele par§1ale ale lul L P Z
in raport cu variabilele primale w, wO, 5 2:11 041%‘ I 0
§i p §i apoi egaléndu-le cu 0, vom obtine 1
imediat: 04¢ + 61- : E pentru 2' : 1, . . . ,m
2:11 CEZ' — 6 I U.

***************Ending Page***************

***************Beginning Page***************
***************page number:96**************
96.
1 1 1
Din rela§ia 041- + 61- : —, §iné1nd cont c5 al- Z O §i 51' Z 0, rezulté 041- € [0, —] §i 61- € [0, —]
m m m
pentru 1, . . . ,m. De asemenea, din relaigia 2:11 041- — 5 I 1/ rezulté (:5 2:11 042' Z u.
Condigiile de complementaritate KKT sunt: aZ-(yZ-(w - ml- + 1110) — p +51) I O, 5161- I O §i
5p I O.
Substituind w I 2:11 aiyixi in expresia lui L P §i apoi fiicénd diversele simpliﬁcéiri posi-
bile, va rezulta c5 forma dualéi corespunzétoare problemei (P”) este:
1
maxa (— 5 219' aicuij-iji 4133-)
1
. A. < ' < — t ' : 1
a 1 O_042_mpenruz , ,m (DH)

2211 041% I 0

2211 041' Z V-
De remarcat c5
— multiplicatorii Lagrange [31- §i 5 nu apar in (D”);
— in funcgia obiectiv a problemei duale (D”) nu apare termenul 2:11 041-, care era prezent
in func§ia obiectiv a problemei duale atét pentru SVM cu margine “hard” c511; §i pentru
C-SVM;
— in schimb, in partea de restricigii apare conditia suplimentaré 2:11 041- 2 u.

***************Ending Page***************


***************Beginning Page***************
***************page number:97**************
97.
b. Stabiliﬁ rela§iile de legéturéi intre 15, 150, ,5, prin care am notat solutiile
problemei (P”), §i soluigiile problemei duale de la punctul b.
in ce prive§te legéitura dintre solutiile formei primale (P”) §i cele ale formei
duale (D”), avem mai intéi £5 I 2111 @iyixi. Apoi, din condigiile de1 comple-
mentaritate KKT deducem 051 dacéi existéi un 54,- astfel incét O < 54,- < —, atunci
_ _ 771
@1- > O §i deci {@- : O. De asemenea, 541- > O implicii y¢(15 41:, + £50) — 5 —l- £1- : O, de
unde rezultﬁi yi(/u_) - x,- + 150) : ,5.
Folosind aceasté ultiméi relagie, valorile optime 150 §i 5 se vor determina astfel:
dacéi avem x+ 0 instan§€1 pozitivé §i a:_ 0 instanigé negativé astfel incét multipli-
catorii Lagrange corespunzétori sunt in intervalul (0, i) ,a atunci 15-er +150 : ,5
§i 15 - a:_ +150 I —,5. Aceste ultime douéi ecuatii formeazé un sistem din care se
0b§in imediat 150 §i 5:
_ 1 _ _ 1 _
wO I —Ew-(:I:++x_) p:§w-(:r+—:1:_)
Observaiz'e: in articolul despre u-SVM citat in enuntg, autorii extind acest
procedeu de calcul pentru valorile 150 §i 5 la mai multe perechi de instante
pozitive §i respectiv negative, pentru a obtine un rezultat cét mai robust.
a De remarcat c531 dacé existé una din cele doué instange, atunci in mod necesar existé gi cea de-a doua, ﬁindcii
21' 5419i I 0-

***************Ending Page***************

***************Beginning Page***************
***************page number:98**************
98.
c. Care este regula de clasiﬁcare a unei instan§e de test oarecare as’ in acest
model?
Datéi ﬁind o instanigé noué (de test) x’, ea va ﬁ clasiﬁcaté conform expresiei
Sign (Z @iyZ-aii - :13’ + 100) .
1:1

Observatie:
La MIT, 2004 fall, Tommi Jaakkola, HW3, pr. 3.3, pe un set de date [LC:
oarecare] este pusii ilustratfai corelarea intre diferite valori (cresciitoare) ale
lui u §i valorile obiginute de nu-SVM (folosind RBF cu a I 1) pentru erorile
la antrenare §i, respectiv, la testare:

u 0.01 0.1 0.3 0.5 0.7

training error 0 0.01 0.05 0.07 0.18

test error 0.013 0.014 0.073 0.105 0.195
ceea ce araté c5 parametrul u are intr-adevéir efectul de dorit, in sensul c5
numéirul de erori la antrenare cregte [in general] odaté cu valoarea parametru-
lui u.

***************Ending Page***************


***************Beginning Page***************
***************page number:99**************
99.
The one-class SVM (Max Margin) with soft margin
solved using [ the approach/idea from ] u—SVM
MIT, 2009 fall, Tommy Jaakkola, Lecture notes 5
[ adapted by Liviu Ciortuz ]

***************Ending Page***************

***************Beginning Page***************
***************page number:100**************
100.
Aici vom continua sa lucram asupra problemei de optimizare S VM one-class
varianta Maw Margin (vezi Stanford, 2007 fall, Andrew Ng, practice midterm
exam, pr. 4).
Mai intai precizam ca, in ceea ce prive§te versiunea cu margine “hard”, fata
de forma primala pe care am considerat-o in problema mentionata, acum vom
lucra cu o versiune mai generalaza
. 1 2
MW —uw|| - p
2
a. i. w-xz- 2p, pentruz': 1,...,m.
Forma aceasta este mai convenabila pentru obiectz'vul pe care ni-l ﬁxam aici,
acela de a elabora cazul marginii “soft” pentru problema SVM one-class
(varianta Maw Margin) urmand abordarea de tip u-SVM.
V5 reamintim ca u-SVM folose§te un parametru numeric (u) care va functiona
ca margine superioara pentru proportia de erori la antrenare din totalul
instantelor de antrenament.
a Distanta de la hiperplanul de separare optimala 1a vectorii-suport care nu produc erori in raport cu marginea va
ﬁ L.
"72”" . .. . . . . . .
D1n punctul de vedere a1 ,,marg1n11“ geometrlce, n01 am vrea ca [g1] p s5» ﬁe maX1mlzat. Aceasta echlvaleaza cu a
minimiza —p. Aga se justiﬁca (in mod intuitiv) expresia functiei obiectiv din problema de optimizare pe care urmeaza
s51 o formulam.

***************Ending Page***************


***************Beginning Page***************
***************page number:101**************
101.
Forma primala pe care 0 vom considera aici pentru problema u-SVM one-
class (varianta Mam Margin) este de asemenea u§0r schimbata in raport
cu formularea originala a problemei u-SVM (B. Schiilkopf, A. Smola, R.
Williamson §i P. Bartlett, New Support Vector Machines, 2000):
1 1
mmw (2 ||w|| p + m 222151)
a.i. w-acZ-Zp—§¢,pentruz':1,...,m (P)
51' 20 pentruz': 1,...,m.
Remarcati faptul ca in ambele probleme de optimizare date mai sus n-au fost
impuse restrictii asupra variabilei p.
a. Demonstrati ca forma duala corespunzatoare formei primale (P”’) a prob-
lemei u-SVM one-class (Max Margin) este urmatoarea:
1
maxa (— 5 2M oziozjxi 053')
1 ///
a.i. 0§04i§—pentruz':1,...,m (D)
um
2:11 0% Z 1-

***************Ending Page***************

***************Beginning Page***************
***************page number:102**************
102.
Expresia lagrangeanului generalizat este:
1 1
LP(w>§>p>04>5) I 5102 — 0+ $251‘ — 2041110 ' $1‘ —,0+€i) — 25151.
Calculénd derivatele par§iale ale lui L P in raport cu variabilele primale w, 5
§i respectiv ,0, iar apoi egaléndu-le cu 0 vom avea:
8
8—Lp(w,§,p,oz,ﬂ) I O :> w — 210414131‘ I O i w I 21041037;
w
(9 1 1
(95¢ um um
Observajie: intrucét 04¢ Z 0 §i 6i Z 0, rezulté
1 , 1 .
04¢€ 0,— §15i€ O,— pentruz:1,...,m (*)
um um
5
8—Lp(w,§,p,oz,ﬁ):() :> —1+Zia¢:0:>2iozi:1. (aw)
p

***************Ending Page***************


***************Beginning Page***************
***************page number:103**************
103.
Folosind rela§iile acestea, expresia lagrangeanului de mai sus devine:
1 1
522%03-961- “j —P+ $251‘ — ZMZOW) “I
+p 04¢ — (04¢ + 5051' I
2 2W
1
1 n0 .
—§ Z Zaiajxi - xj :t LD(04)
i j
Prin urmare, tinénd cont de restrictiile (*) §i (90%), duala problemei u-SVM
one-class (Max Margin) va avea exact forma indicatéi in enunt; (D”’).

***************Ending Page***************

***************Beginning Page***************
***************page number:104**************
104.
b. Scrieigi condigiile de complementaritate KKT pentru problema primalé
(P”’), apoi arétaﬁ cum anume se poate calcula ﬁ, valoarea rezultaté pentru
variabila p la rezolvarea problemei duale (D”’), in functie de valorile celorlalte
variabile (w, 642-, {2-, etc).
lrlilil'lilﬂii'rI-III1 lhi-iranrmMI-IIIE'
'3 B
25 EE-
i' i’
15 15
1 a 1 a H
05 E DE- $1 i E
a
III m III
a ma
JJEIIII IIIEI 1 15 2 E5 E 435': IIIE- 1 1.5 E 25 i-
Credit: Tommi Jaakkola, MIT,
ML course, 2009 fall, lecture notes 5.

***************Ending Page***************


***************Beginning Page***************
***************page number:105**************
105.
Condiigiile de complementaritate KKT pentru problema primalé (P”’) sunt:
CYZ'(w-£IZ¢ —p+§Z-) :0 §i 61$ :0 pentru 2': 1,...,m.
Valorile care rezulté pentru multiplicatorii Lagrange al- 1a rezolvarea proble-
mei (D”’) conduc la urmétoarele cazuri:
1 _ — . . _ — _. I
. all-e 0,— ioii>0§iﬂi>0g 7;” x1 p+€’ 0 $10-$in
um é} I 0
_ 1 _
Q @¢:0:>3¢:—I2>T§i:0:>w'56125
um
1 _ _ _
o 64,-:—$5¢:0g5120§iw'$i25—51
um

***************Ending Page***************

***************Beginning Page***************
***************page number:106**************
106.
A§adar,
1
— dacii in urma rezolvzirii problemei duale (D”’) existéi un 64¢ € (0, —> , atunci
um
valoarea lui [3 va ﬁ U1 - xi;
1
— altfel, adicEi dacé pentru orice 2' € {1,...,m} avem ﬁe 6w : — ﬁe 5m I O,
um
atunci putem alege pentru ﬁ valoarea valuarea maximéi a lui p astfel incét
Z{i:oz¢:1/(um)}(p — 171 ' $1‘) S Ump-
Obse'rvajz'e (1):
Este imposibil ca 071- : O pentru t0§i 2' : 17 . . . ,m, intrucét 2:11 642- : 1.“ Nici
1

cazul 071- : — pentru t0§i 2' I 1,...,m nu este posibil intrucét aceasta ar

um
implica u I 1 (tot datoritii relaljiei 221 072' I 1 care a fost folositéi §i mai sus),
ceea (:e contravine faptului (:5 pentru I/—SVM avem intotdeauna v E (0,1).

a LC: Mulgumesc lui Sebastian Ciobanu pentru aceasté observagie.

***************Ending Page***************


***************Beginning Page***************
***************page number:107**************
107.
Observatie(2): Prof. Tommi Jaakkola de la MIT a ariitat c5 problema (P’”)
este echivalentéi cu urmiitoarea probleméi (féiré restrictii, inséi folosind functia
de cost hinge):
_ 1 2 1 m
mm —||w|] — ,0 + — Zmax{0,p — w - 33,}
wm 2 I/m .
2:1
§i, in consecintéi, solutia ﬁ se poate alege ca ﬁind cea mai mare valoare a lui
p astfel incét
Zmax{0,p — w - xj} I Zmax{0,p — g 642ml- - mj} 5 ump.
j j 1'
Z Illi-LPLHL ﬁ 7/
i=1 _
_ .-"'
_ .-"'
_ f
_. x
_ x
X
_ X
111:4};{1L J5‘ - 4'7. — if}. lufﬁxﬂl. I‘! - ""2 — In}-
. If‘;
—-—-'—..
f1 - .rrl l5‘ - .1": I“
Credit: Tommi Jaakkola, MIT,
ML course, 2009 fall, lecture notes 5.

***************Ending Page***************

***************Beginning Page***************
***************page number:108**************
108.
The Minimum Enclosing Ball (MEB) problem
solved using u—SVl\/I
MIT, 2009 fall, Tommy Jaakkola, Lecture notes 5
[ adapted by Liviu Ciortuz l

***************Ending Page***************


***************Beginning Page***************
***************page number:109**************
109.
Date ﬁind instantele $1, . . . ,xm € Rd, ne propunem séi gésim 0 sferéi care $5.
includé toate punctele 331- §i $5 aibé cea mai micii razéi posibilé. Pentru aceasta,
formulém urmétoarea problemé de optimizare convexéz
rlglin R2 astfel incét Hw — xZH2 g R2 pentru 2' I 1, . . . ,m.
,w
De remarcat faptul céi restricigiile din formularea acestei probleme sunt de
ordin piitratic (spre deosebire de cazul problemei SVM clasice, in care
restrictiile sunt liniare). La ﬁnalul rezolvéirii acestei probleme,
— valoarea géisitéi pentru w va reprezenta centrul sferei;
— vectorii-suport vor ﬁ punctele xi de pe suprafata sferei; restricgiile core-
spunzétoare lor vor ﬁ satisfécute cu egalitate (Hw — xZHZ I R2).
Ca §i in cazul problemei u-SVM, putem impune c0ndi§ia ca maximum um
puncte (din totalul celor m) $5 ﬁe liisate in afara sferei. Corespunziitor, prob-
lema de optimizare convexé de tip u-SVM va ﬁ:
1 m
min R2 + — -
R,w,€ < Um 2&2) (Pin)
astfel incét Hw — 33i||2 g R2 + £1- pentru 11 I 1, . . . ,m
Si 20 pentruz': 1,...,m.

***************Ending Page***************

***************Beginning Page***************
***************page number:110**************
110.
Observafgie
Aceasta este 0 altéi variantéi a problemei one-class decét varianta M aw M a'r'gz'n.
Tommi Jaakkola (MIT, 2009 fall, HW2, pr. 2.a) a arétat c5 intr-un spagiu
de ,,trés€1turi“ in care ||q5(xZ-)|| I c pentru 2' I 1, . . .,m, unde c este 0 constanté
oarecare, cele douéi variante ale problemei one-class sunt echivalente.
Remarcagi faptul (:51 pentru nucleul RBF aceasté condi§ie este indeplinité,
2
90 — :1:
ﬁindcii ||gb(a:)||2 I K(a;,m) I exp ( — H2—2H) I 1, pentru orice instanté x.
0

***************Ending Page***************


***************Beginning Page***************
***************page number:111**************
111.
a. Demonstratji ca forma duala a problemei de tip u-SVM de mai sus este:
maXa (_ 22-217- OliCYjZEZ' ' 333' + 2:11 (12-901- - 33¢)
1 .
a.i. Ogozi§—pentruz':1,...,m (Dw)
um
221 04%- : 1
unde 04¢ este multiplicatorul Lagrange corespunzator restricigiei i € {1, . . .,m}.
Lagrangeanul generalizat pentru problema de tip u-SVM data in enuni; in
forma primala (Pw)) este:
1 m m m
2:1 2:1 1:1
unde 51- sunt multiplicatorii Lagrange corespunzatori restricgiilor £2- 2 O.

***************Ending Page***************

***************Beginning Page***************
***************page number:112**************
112.

Condiigiile de optimalitate KKT pentru LP se 0b§in egalénd cu O derivatele
sale parigiale in raport cu R, w §i respectiv 52-:

in(R,w,§,01,ﬁ)IO I 2R—2Rio¢iI0Ii011-I1

(9R 1:1 1:1

iLp(112,w,§,01,5)I O I> ZiaZ-(w —a:Z-) I 0 I> w I Liaixi I gym/3011332-

8w 1:1 i041‘ 1:1 1:1

1:1
1

(9 1 1

(951- um I/m
Din ultima rela§ie 0b§inut5 mai sus, §in€1nd cont 05 al- Z O §i 51' Z 0, rezulté c5

1 1
041€[01—]§i51€[01—lpentrlli: 1,...,m.
um um

***************Ending Page***************


***************Beginning Page***************
***************page number:113**************
113.
inlocuind w cu 2:11 011-ch- in expresia lui L P §i ginénd cont §i de celelalte doué
egalitéiigi deduse mai sus, vom avea:

1 m m m
R2 — 1 1 — 1 2 — R2 — 1' — 1 1'
+Vmgé+gaﬂw 1) £1 gm
1 m m m m m m
I R2 — 1 102 01¢ —2w ozl-xi 011w2 — R2 012- — cm- 1 1
V HF/ V i
1 w 1 um
1:1 1:1 1:1 1:1 1:1
in concluzie, vom regési exact forma dualéi a problemei u-SVM din enung.

***************Ending Page***************

***************Beginning Page***************
***************page number:114**************
114.
b. Indicaﬁ relaigia de legéturfi dintre solugia z?) a problemei primale §i soluigia
64 a problemei duale. (RemarcaQi semniﬁcaQia geometricé a rezultatului!)
Conform rezultatului de la punctul a, vom avea: w I 2:11 072-3”. Aceasta
inseamné c5 centrul sferei de incluziune minimalé este media ponderaté a
instantelor xi, ponderile ﬁind chiar multiplicatorii Lagrange 64¢.
c. Cum se poate calcula valoarea optiméi R (pentru variabila R din forma
primalé (Pi”)) pornind de la solutia problemei duale?
Sugestz'e: Pentru aceasta, este util ca, pentru problema de tip u-SVM de mai
sus (Div), s51 enuntaigi condiigiile de complementaritate KKT.

***************Ending Page***************


***************Beginning Page***************
***************page number:115**************
115.
Condiigiile de complementaritate KKT sunt: d¢[(w—a:i)2 —R2 —§Z-] I O §i 3251- I O,
pentru i I 1,...,m.
Solutia pentru R se obii'ine din aceste doué condi§ii, §i anume:
— dacii existé un 2' astfel incét 641- > O, atu_nci din prima c0ndi§ie de comple-
mentaritate KKT rezulté R2 I (112 — 33,-)2 — £1;
1 _ 1 _
— dacéi, in plus, 647; < —, atunci din egalitatea 64¢ + 51' I — rezulté c5 52' > 0;
z/m um
mai depiirte, in baza cel_ei de-a doua c0ndi§ii de complementaritate KKT, va
rezulta 5i I 0. A§adar, R2 I (w — 51:1‘)?
Observatiz':
1. Evident, in solutia problemei duale va exista cel putin un 07¢ > O, ﬁindcéi
22-541‘ I 1 §i 64¢ 20 pentruz'I 1,...,m.
1
2. Dacii in soluigia problemei duale nu existéi niciun 64¢ astfel incét O < 64¢ < —,
um
A v v . _ _ 1 . . v . .
1nseamna ca pentru orlce 042- 75 0 avem 041- I —. Atunc1, datorlta rela§1e1
um
_ 1 _ _ A
641+ Bi I —, vom avea c5 orice 64¢ I 0 implicé Bi I 0 §i deci 5i > O. In aceasté
um _
situaigie, vorn putea lua R I maxﬁ z @i:0}(w — $02.

***************Ending Page***************

***************Beginning Page***************
***************page number:116**************
116.

3 a

E . E

i .
I 1| 1- r- |,l I ti-
"* 1-
n H * 1 _ u
I- ‘ i ‘- " q.
4 -, i * i * ' -1
. i 1- ‘ ._ ;'|

“I? a i. —E H
-a . -:a
—4 —I1-

—-‘E —E —'1- —2 {I E 11- E —iE| —E —4 —E [I E 11- E

Linear kernel, 1/ : 0 Linear kernel, 1/ : 0.1

***************Ending Page***************


***************Beginning Page***************
***************page number:117**************
117.
3 ""F 3 -
E + 2
* 1-
4- , i
-| + 1- 1 r 1 El
"' r . '|
'3' i‘ i . u '5
I- i 'I' "'
‘1| II +
—1 . * ' -1
||I ‘I I- 1| I E
-2 ... ' -2
i
-a . -:a
_4
-a -a -4 -2 n 2 4 a in 45 -4 -2 n 2 4 a
Quadratic kernel, 1/ : O Quadratic kernel, u I 0.1

***************Ending Page***************

***************Beginning Page***************
***************page number:118**************
1 18.
3
a
E
u 3'"
1 'J- "1'6 i
| ‘I’ I.
n ""
__ 1|
_1 '
r, Gaussian kernel, u = 0.1
—E
F;-
_3 'i."'
_4
—iB —E —I1- —E [I 2 J1- E
Gaussian kernel, u : 0

***************Ending Page***************


***************Beginning Page***************
***************page number:119**************
119.
SVR — Support Vector Regression,
the hard margin version
Stanford, 2014 fall, Andrew Ng, midterm, pr. 4

***************Ending Page***************

***************Beginning Page***************
***************page number:120**************
120.
Until now, we saw how the SVM can be used for classiﬁcation. In this prob-
lem, we will develop a modiﬁed algorithm, called the Support Vector Re-
gression (SVR) algorithm, which can instead be used for regression, with
continuous valued labels y 6 R.
Suppose we are given a training set {($1,y1), . . . , (56m, ym)}, where x,- € Rn+l and
y,- € R. We would like to ﬁnd a hypothesis of the form hw,b(a:) I w - x + b with
a small value of Hw||. Our (convex) optimization problem is:
1
w,b 2
s.t.y,—(w-a:,-+b)§5(i:1,...,m) (24)
(w-zci+b)—yi§e(i:1,...,m). (25)
where a > 0 is a given, ﬁxed value. Notice how the original functional mar-
gin constraint has been modiﬁed to now represent the distance between the
continuous y and our hypothesis’ output.

***************Ending Page***************


***************Beginning Page***************
***************page number:121**************
121.

a. Write down the Lagrangian for the optimization problem above. We

suggest that you use two sets of Lagrange multipliers 04¢ and 04;‘, corresponding

to the two inequality constraints (labeled (24) and (25) above), so that the
Lagrangian would be written L(w, b, d, 04*).

Let ai, 04;k Z O (2' : 1, . . . ,m) be the Lagrange multiplier for (24) and (25) respec-

tively. Then, the Lagrangian can be written as:

1 m m
L(w,b,d,d*) I §Hw||2 +;ozi(yi —w-xi —b—5) +;d§(—yi +w-atz- +b—6).

***************Ending Page***************

***************Beginning Page***************
***************page number:122**************
122.
b. Derive the dual optimization problem. You will have to take derivatives
of the Lagrangian with respect to w and b.
First, the dual objective function can be written as:
LD(a,a*) I milnL(w,b,oz,oz*).
w?

Now, taking the derivatives of Lagrangian with respect to all primal variables,
and equating them to O, we have:

(9L m * m *

% I w—2(04,- —ozi)x,- :0 :> w :E(oz,- —oz,;)zc,-

1:1 1:1
(9L m *
1:1

***************Ending Page***************


***************Beginning Page***************
***************page number:123**************
123.
Substituting the above two relations back into L(w, b, 01, 01*), we have:
1 m m
LD(01,01*) I §Hw||2 +2014?” —w-:I:Z- —b—€) +201I(—y1+w-x¢+b—e)
1 m >i< m >i<
I 5HIU||2 — 52(041 + 041) + 291(041— 041)
1:1 1:1
—2(01¢—a2<)w-x¢—b2(01¢ —012<)
1:1 1:1
W
0
1 m >l< m >l< m >|<
I 5112(041 —O¢1)$1||2 —62(a1+011)+2y1(011—0q)
1:1 1:1 1:1
— Z(@1— 01;) 2(041 — @§)$1'$1
1:1 1:1
1 m m * * m * m *
I —§ EZ(@1— 041-)(041 — 041W ' 551 — 62(011+ 041-) + Zy1(011— 041)-
1:1 1:1 1:1 1:1

***************Ending Page***************

***************Beginning Page***************
***************page number:124**************
124.
Now the dual problem can be formulated as:
1 m m m m
{223$ (— 52321041‘ —@l)(aj —O¢§)$1'$j —€Z(041+04§<) +Zy1l041' —041-k))
m
s. t. 23(012- —oz:) I O
1:1
011501: Z O (1': l,...,m).
c. Show that this algorithm can be kernelized. For this, you have to show that
(2') the dual optimization objective can be written in terms of inner-products
of training examples, and (ii) at test time, given a new x, the hypothesis
hwjb(a:) can also be computed in terms of inner products.
This algorithm can be kernelized because when making prediction at m, we
have:
m m
f(w,$) I w-a:+b: 2(016- —oz;<)a:¢ ~x+b: 2(oq —01;-k)k(xi,w) +b.
1:1 1:1
This shows that predicting function can be written in a kernel form.

***************Ending Page***************


***************Beginning Page***************
***************page number:125**************
125.
SVR — Support Vector Regression,
using the s-sensitive loss function
CMU, 2014 spring, B. Poczos, A. Singh, HW2, pr. 1
CMU, 2015 fall, Z. Bar-Joseph, E. Xing, HW3, pr. 2.1-4

***************Ending Page***************

***************Beginning Page***************
***************page number:126**************
126.
In this exercise you have to derive the dual form of the support vector regres-
sion (SVR) optimization problem, using the epsilon sensitive loss function.
not.
L@(w,y,f) I ly—f(w)|@ I maX(0,ly—f(fB)\ —.¢;). (26)
Here a: is the input, y is the output, and ﬁx) déf' w - :13 is the function used for
predicting the label.
Your training data is (5E1,y1),. . ., (:tmyn), Where :10,- € Rm, y,- € R.
[Note that the hinge loss that we used at CMU, 2008 fall, Eric Xing, HW2,
pr. 1.2 is only designed for classiﬁcation, we cannot use that for regression]
Using this notation, the SVR objective function is deﬁned as
1 2 n
1:1
Where f(:v) I w - x, and C,s > 0 are parameters.

***************Ending Page***************


***************Beginning Page***************
***************page number:127**************
a. Introduce appropriate slack variables, and rewrite this problem as a quadratic prob- 127_
lem (i.e. quadratic objective with linear constraints). This form is called the primal
form of the SVR optimization problem.
In the above loss function, a deﬁnes the region inside which errors are ignored. Note
that the a-sensitive loss function (26) is non-differentiable due to the absolute value in the
loss function. We can introduce slack variables i and §* to account for errors in points
that lie outside the tube (similarly to the way slack variables used in classiﬁcation)“
y¢—w-w¢—€ S éz' (27)
w-ch-—yi—€ g 5; (28)
ﬁiff Z 0fori:1,...,n (29)
Thus, we can rewrite the primal form as,
1 TL
- 2 >2<
IIllIl — w + C - + ' >
MRWWW (2 u || gs. m
s.t. equations (27)—(29) are satisﬁed.
a Note that the relationships (27) and (28) are equivalent to the following ones:
w'l'z' Zyi—5—€i
w-wi gyi+€+€i

***************Ending Page***************

***************Beginning Page***************
***************page number:128**************
128.
b. Write down the Lagrangian function for the above primal form.
Having the above objective and constraints, the Lagrangian function can be
written as follows.
not. * * *
1 n >1< n * >|<
I 5|le2 + CZQZ- +50 — Dm- + m)
1:1 1:1
_Zai(5+€i_yi+w'$i) —2042<(5+§§k +yi—w'$i)>
1;:1 1:1
where the Lagrange multipliers have to satisfy the positivity constraints
ai,a;k,ﬂi,ﬂf Z O, for 2' I 1,...,n.

***************Ending Page***************


***************Beginning Page***************
***************page number:129**************
129.
c. Using the Karush-Kunh- Tucker conditions derive the dual form.
We need to solve the following min-max problem:
w7£1€>k Q,O£2<,B,B*
I arg max min L(w,§,§*,a,a:,6,6*) (32)
04704:,ﬁ75* wagaéfk
[The max and min can be switched because the so-called strong duality holds
for SVR problems similarly to SVM problems (see CMU, 2010 fall, Ziv Bar-
Joseph, HW4, pr. 1.3-5 and CMU, 2012 spring, Ziv Bar-Joseph, HW3, pr. 3.2).]
Taking the derivative of L W.r.t. the primal variables w, £7; and if, and then equating
them t0 O, we get
8L n *
8—w :w—;(ozi—ozi)zc¢:0
g—§;:C—ozi—ﬂl-:0 and g—gk:C—a;-k—5§k20, fori:1,...,n.
From the last two equations we have that
OgBZ-zC-ai and Ogﬂf:C—a;-kfori:l,...,n.

***************Ending Page***************

***************Beginning Page***************
***************page number:130**************
130.
Substituting the results back into the Lagrangian (30), we get
LD ‘32> luwng + Cie- + 5*) - fez-51+ we)
2 1-:1 Z iIl z 2
—204i(6+§¢—y¢+w-93¢) —Zoz§<(e+§f+yi—w-a:i)
izl 1:1
1 n * n n >|< >s< >|<
I 5H 21042‘ _ 04¢)l'z'H2 +251‘ (C—5¢ — (IU-I-Zgi (C— 61- — 041-)
izl 1:1 \_O,—/ izl _0/—/
—<§ (04i+04;~k)+ yi(O¢¢—OlI)— (04@—O¢I) w-ari
(2?:1(Olj—a§)$j)'wi
1 n n >|< >!< n * n >|<
I —§ 22%‘ — 0%‘)(041 — 04].);131- 'wj — 62w +041) + ZyZ-(m — 0%)- (33)
1'21 i=1 1:1 1:1

***************Ending Page***************


***************Beginning Page***************
***************page number:131**************
131.
Therefore, the dual problem is
1 TL TL * * TL * TL *
mgX (— 522(041—04i)(04j —@j>wi-wj —€Z<@Z-+@i> +Zyi<ai w»)
1:1 j:1 1:1 i=1

s. t. 041504: E [0,C] for 2' : 1,...,n.
[Note that if you use w-x-l-b instead of w-x, then you have an extra constraint:
221:1(041' _ 04:) I 0']

***************Ending Page***************


***************Beginning Page***************
***************page number:132**************
132.
d. Can we use quadratic optimization solvers to solve the dual problem?
The problem has a quadratic objective with linear constraints, therefore it
can be solved by a Quadratic Programming solver.
e. How would you deﬁne support 'vecto'rs in this problem?
The KKT complementary slackness conditions are as follows. In the optimal
solutions of (31) and (32) we have that
af(e+§f +y¢—w-a3,~) I O

51'51' I 0

6:5? I 0
for alli: 1,...,n.
Equation (34) implies that if a,- > 0, then (5 + £2- — yi + w - x2) I O.
Now, if 5i I O (which implies 5i € [0,0] and therefore a7; € [0,C] too), then it
means that sci is on the border of the e-tube, therefore sci is a margin support
vector. If é}- > 0 (which implies 61' I O and therefore 042- : C), then it means that
we are outside of the s-tube. These m2- vectors are the non-margin support
vectors. Similar reasoning holds for 5;‘ and 04;‘.

***************Ending Page***************


***************Beginning Page***************
***************page number:133**************
133.

f. Write down the equation that can be used for predicting the label of an
unseen sample X.
Since for prediction we use f(:r) I w - ac, and w I 2?:1(a, — 04:)3UZ', therefore

far) I 2w.- — a?) w.- - w- <35)

1:1

g. Is it possible to kernelize this algorithm?
Yes, in (33) and (35) the Lufs appear only as arguments of the dot product,
therefore they can be written in the kernel form.
h. Give one reason why do we usually solve the dual problem of SVR and
SVM instead of the primal.
Because we can introduce kernel functions here [LC: so we can (hopefully)
get better hypotheses in the feature space, and also because kernel values can
be efficiently computed].

***************Ending Page***************


***************Beginning Page***************
***************page number:134**************
134.
i. What happens if we change e? e plays the opposite role of C. The smaller
the value of e, the harder SVR tries to fit smaller errors around the learnt
SVR function, and leads to a more complex model. Smaller e also leads to a
less sparse solution (more support vectors).
Small e — More complex model. Low Bias, High variance.
Large e — Less complex model. High Bias, Low Variance.
j. What happens if we change C?
C plays a similar role as it did during classiﬁcation. It is a measure of how
strongly we penalize errors. It should be tuned for bias vs. variance with
model selection. The higher the value of C, the larger the tendency of SVM
to penalize errors and ove'rﬁt the data. The lower the value of C, the larger
its tendency to ignore errors and underﬁt the data.
Large C — More complex model. Low Bias, High variance.
Small C — Less complex model. High Bias, Low Variance.

***************Ending Page***************


***************Beginning Page***************
***************page number:135**************
135.
Exempllﬁcation
Ll'u-I'Hlml HEh'I-m-ll

E 2
LB- LB
LE- lE-
I.Il- n4; Lul- I‘.
1.2 1.2

u .-_' I ii
I n I I ‘I H
I I I I! u. ‘I
M I: Il I‘ H - ‘- -.l u J-Iﬂ.‘ I u E n r.
I _ I " _'-_-
I15 ' I15
‘1-4 llil-
.-" -.’+'
I12 I "5' u _
u I
IIII I]
I] ELI [LE I13 I14 li'j- l]'.E- l1? II'H- I15 l '1 ‘1| '12 '15 '1"- M '1']- l1? '15 '1'!’ I
Credit: CMU, 2014 fall, Eric Xing, Barnabas Poczos, HW2, pr. 1.2.4

***************Ending Page***************

