[{content={parts=[{text=--FlashCardSeparator--
Single
--InteriorSeparator--
Who developed the Perceptron, the first functional neural network?
--InteriorSeparator--
Rosenblatt
--InteriorSeparator--
Easy
--InteriorSeparator--
3
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following are types of machine learning?
--InteriorSeparator--
(right) Supervised
(right) Unsupervised
(wrong) Reinforcement
(wrong) Semi-Supervised
--InteriorSeparator--
Medium
--InteriorSeparator--
8
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the context of neural networks, what does "training" primarily involve?
--InteriorSeparator--
Determining the parameters of the network using training data
--InteriorSeparator--
Easy
--InteriorSeparator--
7
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What type of output does a regression application provide?
--InteriorSeparator--
Continuous
--InteriorSeparator--
Medium
--InteriorSeparator--
10
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What is the purpose of the activation function in a perceptron?
--InteriorSeparator--
(right) To introduce non-linearity
(wrong) To normalize data
(wrong) To reduce dimensionality
(right) To decide if a neuron should be activated or not
--InteriorSeparator--
Medium
--InteriorSeparator--
12
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the equation of the hyperplane in the context of perceptrons?
--InteriorSeparator--
W * X = 0
--InteriorSeparator--
Easy
--InteriorSeparator--
15
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which boolean function cannot be represented by a single perceptron?
--InteriorSeparator--
(right) XOR
(wrong) AND
(wrong) OR
(wrong) NOT
--InteriorSeparator--
Medium
--InteriorSeparator--
17
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the perceptron training rule, what does the learning rate (η) represent?
--InteriorSeparator--
A positive constant that controls the step size of weight adjustments
--InteriorSeparator--
Medium
--InteriorSeparator--
20
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
According to the perceptron training rule, what happens to the weights if the example is classified correctly?
--InteriorSeparator--
The weights are not updated
--InteriorSeparator--
Easy
--InteriorSeparator--
21
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
Under what condition does the perceptron training procedure converge to a vector of weights that correctly classifies all training examples?
--InteriorSeparator--
When the training examples are linearly separable and η is sufficiently small
--InteriorSeparator--
Hard
--InteriorSeparator--
22
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the primary difference between the Perceptron training rule and the Delta rule?
--InteriorSeparator--
The Delta rule uses gradient descent
--InteriorSeparator--
Medium
--InteriorSeparator--
24
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
In Gradient Descent, what does the gradient specify?
--InteriorSeparator--
(right) The direction that produces the steepest ascent in E (error)
(wrong) The minimum error value
(wrong) The optimal learning rate
(wrong) The direction that produces the least change in E (error)
--InteriorSeparator--
Medium
--InteriorSeparator--
26
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In stochastic gradient descent, how are weights updated?
--InteriorSeparator--
Incrementally, calculating the error for each individual example
--InteriorSeparator--
Medium
--InteriorSeparator--
29
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is another name for the delta rule?
--InteriorSeparator--
LMS (least-mean-square) rule / Adaline rule
--InteriorSeparator--
Medium
--InteriorSeparator--
29
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What is a feed-forward neural network composed of?
--InteriorSeparator--
(right) An input layer
(right) One or more hidden layers
(right) An output layer
(wrong) Feedback loops
--InteriorSeparator--
Easy
--InteriorSeparator--
31
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What property of neural networks allows them to approximate any continuous real function, given enough neurons?
--InteriorSeparator--
Universal approximation property
--InteriorSeparator--
Hard
--InteriorSeparator--
33
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is the formula for the sigmoid function?
--InteriorSeparator--
σ(y) = 1 / (1 + e^(-y))
--InteriorSeparator--
Medium
--InteriorSeparator--
34
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
Which of the following are common non-linear activation functions used in neural networks?
--InteriorSeparator--
(right) Sigmoid
(right) ReLU
(wrong) Linear
(wrong) Step
--InteriorSeparator--
Medium
--InteriorSeparator--
35
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a limitation of a multi-layer perceptron with linear activation functions?
--InteriorSeparator--
It is equivalent to a single-layer perceptron
--InteriorSeparator--
Hard
--InteriorSeparator--
36
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What does the Backpropagation algorithm use to minimize the error between the network output and desired values?
--InteriorSeparator--
Gradient descent
--InteriorSeparator--
Easy
--InteriorSeparator--
38
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are the two main phases of the Backpropagation algorithm?
--InteriorSeparator--
(right) Forward propagation
(right) Backward propagation of error
(wrong) Data normalization
(wrong) Feature selection
--InteriorSeparator--
Easy
--InteriorSeparator--
39
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
During the forward pass in Backpropagation, how are the outputs of neurons in the hidden layer calculated?
--InteriorSeparator--
oh = σ(∑ Whixi) from i=0 to n
--InteriorSeparator--
Medium
--InteriorSeparator--
41
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In Backpropagation, how are error gradients calculated for output units?
--InteriorSeparator--
δk = (tk - ok) * ok * (1 - ok)
--InteriorSeparator--
Hard
--InteriorSeparator--
42
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In Backpropagation, what is the formula for calculating the error gradient for hidden units?
--InteriorSeparator--
δh = oh * (1 - oh) * ∑(th * δk) where k is in outputs
--InteriorSeparator--
Hard
--InteriorSeparator--
42
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In Backpropagation, what is the formula for weight update?
--InteriorSeparator--
Wji <- Wji + ΔWji, where ΔWji = η * δj * xi
--InteriorSeparator--
Medium
--InteriorSeparator--
43
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the context of Backpropagation, what is 'Downstream(j)'?
--InteriorSeparator--
The set of units whose immediate inputs include the output of unit j
--InteriorSeparator--
Hard
--InteriorSeparator--
45
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a key characteristic of batch learning in neural networks?
--InteriorSeparator--
Weights are updated only once after presenting all training vectors
--InteriorSeparator--
Medium
--InteriorSeparator--
50
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
In the "momentum" variant of Backpropagation, what does the momentum constant (α) represent?
--InteriorSeparator--
Inertia that influences the weight adjustment based on the previous epoch.
--InteriorSeparator--
Hard
--InteriorSeparator--
51
--FlashCardSeparator--

--FlashCardSeparator--
Single
--InteriorSeparator--
What is a common technique to mitigate overfitting in neural networks?
--InteriorSeparator--
Weight decay or k-fold cross-validation
--InteriorSeparator--
Medium
--InteriorSeparator--
52
--FlashCardSeparator--

--FlashCardSeparator--
Multiple
--InteriorSeparator--
What are the key stages in designing neural networks?
--InteriorSeparator--
(right) Architecture design
(right) Training
(right) Validation
(wrong) Data Cleaning
--InteriorSeparator--
Easy
--InteriorSeparator--
53
--FlashCardSeparator--
}], role=model}, finishReason=STOP, avgLogprobs=-0.12041533973973192}]